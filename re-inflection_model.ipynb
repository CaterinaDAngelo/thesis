{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('morph_df.pkl.gz', 'rb') as f:\n",
    "    morph_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>lemma</th>\n",
       "      <th>form</th>\n",
       "      <th>tense</th>\n",
       "      <th>mode</th>\n",
       "      <th>act/mid/p</th>\n",
       "      <th>gender</th>\n",
       "      <th>case</th>\n",
       "      <th>person</th>\n",
       "      <th>number</th>\n",
       "      <th>lemma_tok</th>\n",
       "      <th>form_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλεται</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 8, 23, 4, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅληται</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 10, 23, 4, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλῃ</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλλεσθε</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 14, 8, 22, 11, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλλεσθε</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 14, 8, 22, 11, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329771</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329772</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329773</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329774</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329775</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290544 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        POS    lemma     form  tense  mode  act/mid/p  gender  case  person   \n",
       "0         2  ἅλλομαι   ἅλεται      1     5          2       0     0       3  \\\n",
       "1         2  ἅλλομαι   ἅληται      1     5          2       0     0       3   \n",
       "2         2  ἅλλομαι      ἅλῃ      1     5          2       0     0       2   \n",
       "3         2  ἅλλομαι  ἅλλεσθε      4     2          2       0     0       2   \n",
       "4         2  ἅλλομαι  ἅλλεσθε      7     1          2       0     0       2   \n",
       "...     ...      ...      ...    ...   ...        ...     ...   ...     ...   \n",
       "329771    0   ζῳώδης   ζῳῶδες      0     0          0       2     5       4   \n",
       "329772    0   ζῳώδης   ζῳῶδες      0     0          0       1     5       4   \n",
       "329773    0   ζῳώδης   ζῳῶδες      0     0          0       3     4       4   \n",
       "329774    0   ζῳώδης   ζῳῶδες      0     0          0       3     5       4   \n",
       "329775    0   ζῳώδης   ζῳῶδες      0     0          0       3     1       4   \n",
       "\n",
       "        number                    lemma_tok                    form_tok  \n",
       "0            2  [37, 14, 14, 18, 15, 4, 12]      [37, 14, 8, 23, 4, 12]  \n",
       "1            2  [37, 14, 14, 18, 15, 4, 12]     [37, 14, 10, 23, 4, 12]  \n",
       "2            2  [37, 14, 14, 18, 15, 4, 12]                [37, 14, 95]  \n",
       "3            1  [37, 14, 14, 18, 15, 4, 12]  [37, 14, 14, 8, 22, 11, 8]  \n",
       "4            1  [37, 14, 14, 18, 15, 4, 12]  [37, 14, 14, 8, 22, 11, 8]  \n",
       "...        ...                          ...                         ...  \n",
       "329771       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329772       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329773       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329774       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329775       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "\n",
       "[1290544 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ά',\n",
       " 'έ',\n",
       " 'ή',\n",
       " 'ί',\n",
       " 'α',\n",
       " 'β',\n",
       " 'γ',\n",
       " 'δ',\n",
       " 'ε',\n",
       " 'ζ',\n",
       " 'η',\n",
       " 'θ',\n",
       " 'ι',\n",
       " 'κ',\n",
       " 'λ',\n",
       " 'μ',\n",
       " 'ν',\n",
       " 'ξ',\n",
       " 'ο',\n",
       " 'π',\n",
       " 'ρ',\n",
       " 'ς',\n",
       " 'σ',\n",
       " 'τ',\n",
       " 'υ',\n",
       " 'φ',\n",
       " 'χ',\n",
       " 'ψ',\n",
       " 'ω',\n",
       " 'ϊ',\n",
       " 'ϋ',\n",
       " 'ό',\n",
       " 'ύ',\n",
       " 'ώ',\n",
       " 'ἀ',\n",
       " 'ἁ',\n",
       " 'ἄ',\n",
       " 'ἅ',\n",
       " 'ἆ',\n",
       " 'ἇ',\n",
       " 'ἐ',\n",
       " 'ἑ',\n",
       " 'ἔ',\n",
       " 'ἕ',\n",
       " 'ἠ',\n",
       " 'ἡ',\n",
       " 'ἤ',\n",
       " 'ἥ',\n",
       " 'ἦ',\n",
       " 'ἧ',\n",
       " 'ἰ',\n",
       " 'ἱ',\n",
       " 'ἴ',\n",
       " 'ἵ',\n",
       " 'ἶ',\n",
       " 'ἷ',\n",
       " 'ὀ',\n",
       " 'ὁ',\n",
       " 'ὄ',\n",
       " 'ὅ',\n",
       " 'ὐ',\n",
       " 'ὑ',\n",
       " 'ὔ',\n",
       " 'ὕ',\n",
       " 'ὖ',\n",
       " 'ὗ',\n",
       " 'ὠ',\n",
       " 'ὡ',\n",
       " 'ὤ',\n",
       " 'ὥ',\n",
       " 'ὦ',\n",
       " 'ὧ',\n",
       " 'ὶ',\n",
       " 'ᾀ',\n",
       " 'ᾄ',\n",
       " 'ᾅ',\n",
       " 'ᾆ',\n",
       " 'ᾇ',\n",
       " 'ᾐ',\n",
       " 'ᾑ',\n",
       " 'ᾔ',\n",
       " 'ᾕ',\n",
       " 'ᾖ',\n",
       " 'ᾗ',\n",
       " 'ᾠ',\n",
       " 'ᾡ',\n",
       " 'ᾤ',\n",
       " 'ᾦ',\n",
       " 'ᾧ',\n",
       " 'ᾰ',\n",
       " 'ᾱ',\n",
       " 'ᾳ',\n",
       " 'ᾴ',\n",
       " 'ᾶ',\n",
       " 'ᾷ',\n",
       " 'ῃ',\n",
       " 'ῄ',\n",
       " 'ῆ',\n",
       " 'ῇ',\n",
       " 'ῐ',\n",
       " 'ΐ',\n",
       " 'ῖ',\n",
       " 'ῠ',\n",
       " 'ῥ',\n",
       " 'ῦ',\n",
       " 'ῳ',\n",
       " 'ῴ',\n",
       " 'ῶ',\n",
       " 'ῷ',\n",
       " '’']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creo un vocabolario dei caratteri\n",
    "all_characters = set()\n",
    "\n",
    "def collect_unique_chars(word):\n",
    "    for char in word:\n",
    "        all_characters.add(char)\n",
    "\n",
    "morph_df[\"lemma\"].apply(collect_unique_chars)\n",
    "morph_df[\"form\"].apply(collect_unique_chars)\n",
    "\n",
    "char_vocab = (sorted(list(all_characters)))\n",
    "char_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo un dizionario che assegna ad ogni carattere un indice\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_vocab)}\n",
    "\n",
    "vocab_chars = len(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['POS', 'lemma', 'form', 'tense', 'mode', 'act/mid/p', 'gender', 'case',\n",
       "       'person', 'number', 'lemma_tok', 'form_tok'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "char_emb_dim = 64\n",
    "max_len = 14\n",
    "input_layers = []\n",
    "# input and embeddings for lemma's characters\n",
    "lemma_input = Input(shape=(None,), name = \"lemma_input\")\n",
    "input_layers.append(lemma_input)\n",
    "lemma_emb = Embedding(input_dim = vocab_chars, output_dim = char_emb_dim, name = \"lemma_emb\")(lemma_input)\n",
    "\n",
    "# #input and embeddings for form's characters\n",
    "# form_input = Input(shape=(None,), name = \"form_input\")\n",
    "# form_emb = Embedding(input_dim = vocab_chars, output_dim = char_emb_dim, name = \"form_emb\")(form_input)\n",
    "\n",
    "\n",
    "# for the features the embeddings will be repeated for every character\n",
    "# input and embeddings for POS\n",
    "pos_input = Input(shape = (1,), name = \"pos_input\")\n",
    "input_layers.append(pos_input)\n",
    "vocab_pos = len(morph_df['POS'].unique())\n",
    "pos_emb_dim = 8\n",
    "pos_emb = Embedding(input_dim = vocab_pos, output_dim = pos_emb_dim, name = \"pos_emb\")(pos_input)\n",
    "pos_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(pos_emb)\n",
    "\n",
    "# input and embeddings for tense\n",
    "tense_input = Input(shape = (1,), name = \"tense_input\")\n",
    "input_layers.append(tense_input)\n",
    "vocab_tense = len(morph_df['tense'].unique())\n",
    "tense_emb_dim = 16\n",
    "tense_emb = Embedding(input_dim = vocab_tense, output_dim = tense_emb_dim, name = \"tense_emb\")(tense_input)\n",
    "tense_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(tense_emb)\n",
    "\n",
    "# input and embedding for mode \n",
    "mode_input = Input(shape = (1,), name = \"mode_input\")\n",
    "input_layers.append(mode_input)\n",
    "vocab_mode = len(morph_df['mode'].unique())\n",
    "mode_emb_dim = 16\n",
    "mode_emb = Embedding(input_dim = vocab_mode, output_dim = mode_emb_dim, name = \"mode_emb\")(mode_input)\n",
    "mode_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(mode_emb)\n",
    "\n",
    "# input and embedding for diathesis\n",
    "diath_input = Input(shape = (1,), name = \"diath_input\")\n",
    "input_layers.append(diath_input)\n",
    "vocab_diath = len(morph_df['act/mid/p'].unique())\n",
    "diath_emb_dim = 8\n",
    "diath_emb = Embedding(input_dim = vocab_diath, output_dim = diath_emb_dim, name = \"diath_emb\")(diath_input)\n",
    "diath_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(diath_emb)\n",
    "\n",
    "# input and embedding for gender\n",
    "gender_input = Input(shape = (1,), name = \"gender_input\")\n",
    "input_layers.append(gender_input)\n",
    "vocab_gender = len(morph_df['gender'].unique())\n",
    "gender_emb_dim = 8\n",
    "gender_emb = Embedding(input_dim = vocab_gender, output_dim = gender_emb_dim, name = \"gender_emb\")(gender_input)\n",
    "gender_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(gender_emb)\n",
    "\n",
    "# input and embedding for case\n",
    "case_input = Input(shape = (1,), name = \"case_input\")\n",
    "input_layers.append(case_input)\n",
    "vocab_case = len(morph_df['case'].unique())\n",
    "case_emb_dim = 16\n",
    "case_emb = Embedding(input_dim = vocab_case, output_dim = case_emb_dim, name = \"case_emb\")(case_input)\n",
    "case_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(case_emb)\n",
    "\n",
    "# input and embedding for person\n",
    "person_input = Input(shape = (1,), name = \"person_input\")\n",
    "input_layers.append(person_input)\n",
    "vocab_person = len(morph_df['person'].unique())\n",
    "person_emb_dim = 8\n",
    "person_emb = Embedding(input_dim = vocab_person, output_dim = person_emb_dim, name = \"person_emb\")(person_input)\n",
    "person_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(person_emb)\n",
    "\n",
    "# input and embedding for number\n",
    "number_input = Input(shape = (1,), name = \"number_input\")\n",
    "input_layers.append(number_input)\n",
    "vocab_number = len(morph_df['number'].unique())\n",
    "number_emb_dim = 8\n",
    "number_emb = Embedding(input_dim = vocab_number, output_dim = number_emb_dim, name = \"number_emb\")(number_input)\n",
    "number_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(number_emb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now concatenate all the embeddings:\n",
    "\n",
    "combined_embedding = Concatenate()([\n",
    "    lemma_emb,  # character embeddings for lemma\n",
    "    pos_emb_rep,  # POS embedding\n",
    "    tense_emb_rep,  # tense embedding for verbs/participles\n",
    "    mode_emb_rep,  # mode embedding for verbs/participles\n",
    "    diath_emb_rep,  # diathesis for verbs/participles\n",
    "    gender_emb_rep,  # gender for nouns/participles\n",
    "    case_emb_rep,  # case for nouns/participles\n",
    "    person_emb_rep,  # person for verbs\n",
    "    number_emb_rep, # number for verbs/nouns/participles\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now add lstm and dense layer\n",
    "\n",
    "lstm_output = LSTM(128, return_sequences=True)(combined_embedding)\n",
    "\n",
    "output = Dense(vocab_chars, activation = \"softmax\")(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " pos_input (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " tense_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " diath_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " gender_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " case_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " person_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " number_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lemma_input (InputLayer)    [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " pos_emb (Embedding)         (None, 1, 8)                 24        ['pos_input[0][0]']           \n",
      "                                                                                                  \n",
      " tense_emb (Embedding)       (None, 1, 16)                128       ['tense_input[0][0]']         \n",
      "                                                                                                  \n",
      " mode_emb (Embedding)        (None, 1, 16)                96        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " diath_emb (Embedding)       (None, 1, 8)                 32        ['diath_input[0][0]']         \n",
      "                                                                                                  \n",
      " gender_emb (Embedding)      (None, 1, 8)                 32        ['gender_input[0][0]']        \n",
      "                                                                                                  \n",
      " case_emb (Embedding)        (None, 1, 16)                96        ['case_input[0][0]']          \n",
      "                                                                                                  \n",
      " person_emb (Embedding)      (None, 1, 8)                 40        ['person_input[0][0]']        \n",
      "                                                                                                  \n",
      " number_emb (Embedding)      (None, 1, 8)                 24        ['number_input[0][0]']        \n",
      "                                                                                                  \n",
      " lemma_emb (Embedding)       (None, None, 64)             7040      ['lemma_input[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_16 (Lambda)          (None, 14, 8)                0         ['pos_emb[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_17 (Lambda)          (None, 14, 16)               0         ['tense_emb[0][0]']           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lambda_18 (Lambda)          (None, 14, 16)               0         ['mode_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_19 (Lambda)          (None, 14, 8)                0         ['diath_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_20 (Lambda)          (None, 14, 8)                0         ['gender_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_21 (Lambda)          (None, 14, 16)               0         ['case_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_22 (Lambda)          (None, 14, 8)                0         ['person_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_23 (Lambda)          (None, 14, 8)                0         ['number_emb[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 14, 152)              0         ['lemma_emb[0][0]',           \n",
      " )                                                                   'lambda_16[0][0]',           \n",
      "                                                                     'lambda_17[0][0]',           \n",
      "                                                                     'lambda_18[0][0]',           \n",
      "                                                                     'lambda_19[0][0]',           \n",
      "                                                                     'lambda_20[0][0]',           \n",
      "                                                                     'lambda_21[0][0]',           \n",
      "                                                                     'lambda_22[0][0]',           \n",
      "                                                                     'lambda_23[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 14, 128)              143872    ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 14, 110)              14190     ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 165574 (646.77 KB)\n",
      "Trainable params: 165574 (646.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = input_layers, outputs = output)\n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we split the dataframe into training, validation and test set\n",
    "train_df, temp_df = train_test_split(morph_df, test_size=0.3, stratify=morph_df['POS'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['POS'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length covering 95% of lemmata: 12\n",
      "Max length covering 95% of forms: 14\n"
     ]
    }
   ],
   "source": [
    "# we try to determine the best max_len to pad the inflected forms and lemmata\n",
    "# first we understand the distribution of lemmata and inflected forms' length\n",
    "\n",
    "morph_df['lemmata_length'] = morph_df[\"lemma_tok\"].apply(len)\n",
    "morph_df['forms_length'] = morph_df[\"form_tok\"].apply(len)\n",
    "\n",
    "max_len_lemmata = int(morph_df['lemmata_length'].quantile(0.95))\n",
    "print(f\"Max length covering 95% of lemmata: {max_len_lemmata}\")\n",
    "max_len_forms = int(morph_df['forms_length'].quantile(0.95))\n",
    "print(f\"Max length covering 95% of forms: {max_len_forms}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we now create arrays for all the df_train columns\n",
    "pos_train = np.array(train_df[\"POS\"])\n",
    "lemma_train = pad_sequences(np.array(train_df[\"lemma_tok\"]), maxlen= max_len, padding = 'post', truncating = 'pre')\n",
    "tense_train = np.array(train_df[\"tense\"])\n",
    "mode_train = np.array(train_df[\"mode\"])\n",
    "diath_train = np.array(train_df[\"act/mid/p\"])\n",
    "gender_train = np.array(train_df[\"gender\"])\n",
    "case_train = np.array(train_df[\"case\"])\n",
    "person_train = np.array(train_df[\"person\"])\n",
    "number_train = np.array(train_df[\"number\"])\n",
    "\n",
    "# then we create the labels\n",
    "y_train = pad_sequences(np.array(train_df[\"form_tok\"]), maxlen = max_len, padding = 'post', truncating = 'pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do the same for the validation set\n",
    "pos_val = np.array(val_df[\"POS\"])\n",
    "lemma_val = pad_sequences(np.array(val_df[\"lemma_tok\"]), maxlen= max_len, padding = 'post', truncating = 'pre')\n",
    "tense_val = np.array(val_df[\"tense\"])\n",
    "mode_val = np.array(val_df[\"mode\"])\n",
    "diath_val = np.array(val_df[\"act/mid/p\"])\n",
    "gender_val = np.array(val_df[\"gender\"])\n",
    "case_val = np.array(val_df[\"case\"])\n",
    "person_val = np.array(val_df[\"person\"])\n",
    "number_val = np.array(val_df[\"number\"])\n",
    "\n",
    "y_val = pad_sequences(np.array(val_df[\"form_tok\"]), maxlen = max_len, padding = 'post', truncating = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {\n",
    "    'pos_input': pos_train,\n",
    "    'lemma_input': lemma_train,\n",
    "    'tense_input': tense_train,\n",
    "    'mode_input': mode_train,\n",
    "    'diath_input': diath_train,\n",
    "    'gender_input': gender_train,\n",
    "    'case_input': case_train,\n",
    "    'person_input': person_train,\n",
    "    'number_input': number_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = {\n",
    "    'pos_input': pos_val,\n",
    "    'lemma_input': lemma_val,\n",
    "    'tense_input': tense_val,\n",
    "    'mode_input': mode_val,\n",
    "    'diath_input': diath_val,\n",
    "    'gender_input': gender_val,\n",
    "    'case_input': case_val,\n",
    "    'person_input': person_val,\n",
    "    'number_input': number_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 5415/28231 [====>.........................] - ETA: 2:57 - loss: 0.9577 - accuracy: 0.7504"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 5, validation_data = (X_val, y_val), batch_size = 32, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
