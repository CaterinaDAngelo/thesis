{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mount/arbeitsdaten/tcl/Users/dangelo_thesis/thesis/.env/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback\n",
      "  backends.update(_get_backends(\"networkx.backends\"))\n",
      "/mount/arbeitsdaten/tcl/Users/dangelo_thesis/thesis/.env/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mount/arbeitsdaten/tcl/Users/dangelo_thesis/thesis/.env/lib64/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/mount/arbeitsdaten/tcl/Users/dangelo_thesis/thesis/.env/lib64/python3.9/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€ğ¤€ CLTK version '1.2.3'. When using the CLTK in research, please cite: https://aclanthology.org/2021.acl-demo.3/\n",
      "\n",
      "Pipeline for language 'Ancient Greek' (ISO: 'grc'): `GreekNormalizeProcess`, `GreekStanzaProcess`, `GreekEmbeddingsProcess`, `StopsProcess`.\n",
      "\n",
      "â¸– ``LatinSpacyProcess`` using Stanza model by Stanford University from https://stanfordnlp.github.io/stanza/ . Please cite: https://arxiv.org/abs/2003.07082\n",
      "â¸– ``LatinEmbeddingsProcess`` using word2vec model by University of Oslo from http://vectors.nlpl.eu/ . Please cite: https://aclanthology.org/W17-0237/\n",
      "\n",
      "â¸ To suppress these messages, instantiate ``NLP()`` with ``suppress_banner=True``.\n"
     ]
    }
   ],
   "source": [
    "from my_functions_improved import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_words = \"Î¿á½–Î½, á½¡Ï‚, á½¥ÏƒÏ„Îµ, á¼Î¬Î½, á¼„ÏÎ±, Î¿á½ÎºÎ¿á¿¦Î½, Ï„Î¿Î¯Î½Ï…Î½, á¼”Ï€ÎµÎ¹Ï„Î±, á¼”Î½Î¸Î±, Ï„ÏŒÏ„Îµ, á¼Î½Ï„Î±á¿¦Î¸Î±\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = [\"á¼‚Î½ Î´á½² ÎºÎ±á½¶ Î±á½Ï„Î¿á½¶ Î²Î¬Î½Ï„ÎµÏ‚ á¼Ï€á½¶ ÎºÎ»Î·á¿–ÏƒÎ¹ ÎºÎ±Î¸á¿–Î¶Î¿Î½\", \"á¼‘Î¾á¿†Ï‚ Î´á¾½ á¼‘Î¶ÏŒÎ¼ÎµÎ½Î¿Î¹ Ï€Î¿Î»Î¹á½´Î½ á¼…Î»Î± Ï„ÏÏ€Ï„Î¿Î½ á¼ÏÎµÏ„Î¼Î¿á¿–Ï‚\", \"á¼”Î½Î¸ÎµÎ½ Î´á½² Ï€ÏÎ¿Ï„Î­ÏÏ‰ Ï€Î»Î­Î¿Î¼ÎµÎ½ á¼€ÎºÎ±Ï‡Î®Î¼ÎµÎ½Î¿Î¹ á¼¦Ï„Î¿Ï\", \"á¼„ÏƒÎ¼ÎµÎ½Î¿Î¹ á¼Îº Î¸Î±Î½Î¬Ï„Î¿Î¹Î¿, Ï†Î¯Î»Î¿Ï…Ï‚ á½€Î»Î­ÏƒÎ±Î½Ï„ÎµÏ‚ á¼‘Ï„Î±Î¯ÏÎ¿Ï…Ï‚\", \"Î½á¿†Î± Î¼á½²Î½ Î¿á¼µ Î³Îµ Î¼Î­Î»Î±Î¹Î½Î±Î½ á¼Î»á½¸Ï‚ Î²Î­Î½Î¸Î¿ÏƒÎ´Îµ á¼”ÏÏ…ÏƒÏƒÎ±Î½\", \"Ï„Î¿á½¶ Î´á½² Ï€ÏÏ…Î¼Î½Î®ÏƒÎ¹á¾½ á¼”Î»Ï…ÏƒÎ±Î½\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrases = [[\"á¼‚Î½ Î´á½² ÎºÎ±á½¶ Î±á½Ï„Î¿á½¶ Î²Î¬Î½Ï„ÎµÏ‚ á¼Ï€á½¶ ÎºÎ»Î·á¿–ÏƒÎ¹ ÎºÎ±Î¸á¿–Î¶Î¿Î½\", \"Î¿á¼± Î´á¾½ Î±á¼¶Ïˆá¾½ Îµá¼´ÏƒÎ²Î±Î¹Î½Î¿Î½ ÎºÎ±á½¶ á¼Ï€á½¶ ÎºÎ»Î·á¿–ÏƒÎ¹ ÎºÎ±Î¸á¿–Î¶Î¿Î½\"], [\"á¼‘Î¾á¿†Ï‚ Î´á¾½ á¼‘Î¶ÏŒÎ¼ÎµÎ½Î¿Î¹ Ï€Î¿Î»Î¹á½´Î½ á¼…Î»Î± Ï„ÏÏ€Ï„Î¿Î½ á¼ÏÎµÏ„Î¼Î¿á¿–Ï‚\"], [\"á¼”Î½Î¸ÎµÎ½ Î´á½² Ï€ÏÎ¿Ï„Î­ÏÏ‰ Ï€Î»Î­Î¿Î¼ÎµÎ½ á¼€ÎºÎ±Ï‡Î®Î¼ÎµÎ½Î¿Î¹ á¼¦Ï„Î¿Ï\"], [\"á¼„ÏƒÎ¼ÎµÎ½Î¿Î¹ á¼Îº Î¸Î±Î½Î¬Ï„Î¿Î¹Î¿, Ï†Î¯Î»Î¿Ï…Ï‚ á½€Î»Î­ÏƒÎ±Î½Ï„ÎµÏ‚ á¼‘Ï„Î±Î¯ÏÎ¿Ï…Ï‚\"], [\"Î½á¿†Î± Î¼á½²Î½ Î¿á¼µ Î³Îµ Î¼Î­Î»Î±Î¹Î½Î±Î½ á¼Î»á½¸Ï‚ Î²Î­Î½Î¸Î¿ÏƒÎ´Îµ á¼”ÏÏ…ÏƒÏƒÎ±Î½\", \"Î½á¿†Î± Î¼á½²Î½ Î¿á½–Î½ Ï€Î¬Î¼Ï€ÏÏ‰Ï„Î¿Î½ á¼Î»á½¸Ï‚ Î²Î­Î½Î¸Î¿ÏƒÎ´Îµ á¼”ÏÏ…ÏƒÏƒÎ±Î½\", \"á¼€Î»Î»á¾½ á¼„Î³Îµ Î½á¿†Î± Î¼Î­Î»Î±Î¹Î½Î±Î½ á¼ÏÏÏƒÏƒÎ¿Î¼ÎµÎ½ Îµá¼°Ï‚ á¼…Î»Î± Î´á¿–Î±Î½\", \"Î½á¿†Î± Î¼á½²Î½ á¼‚Ï Ï€Î¬Î¼Ï€ÏÏ‰Ï„Î¿Î½ á¼ÏÏÏƒÏƒÎ±Î¼ÎµÎ½ Îµá¼°Ï‚ á¼…Î»Î± Î´á¿–Î±Î½\", \"Î½á¿†Î± Î¼á½²Î½ Î¿á¼µ Î³Îµ Î¼Î­Î»Î±Î¹Î½Î±Î½ á¼Î»á½¸Ï‚ Î²Î­Î½Î¸Î¿ÏƒÎ´Îµ á¼”ÏÏ…ÏƒÏƒÎ±Î½\"], [\"Ï„Î¿á½¶ Î´á½² Ï€ÏÏ…Î¼Î½Î®ÏƒÎ¹á¾½ á¼”Î»Ï…ÏƒÎ±Î½\", \"Ï„Îµ Ï€ÏÏ…Î¼Î½Î®ÏƒÎ¹Î± Î»á¿¦ÏƒÎ±Î¹\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "box = 'Ï„Î¿á½¶ Î´á½² Ï€ÏÏ…Î¼Î½Î®ÏƒÎ¹Ê¼ á¼”Î»Ï…ÏƒÎ±Î½ , á¼‚Î½ Î´á½² ÎºÎ±á½¶ Î±á½Ï„Î¿á½¶ Î²Î¬Î½Ï„ÎµÏ‚ á¼Ï€á½¶ ÎºÎ»Î·á¿–ÏƒÎ¹ ÎºÎ±Î¸á¿–Î¶Î¿Î½ .'\n",
    "for cat in paraphrases[0]:\n",
    "    if cat in box:\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword_sentence(lemmata):\n",
    "    sents = []\n",
    "    for corpus_id, corpus in enumerate(corpora):\n",
    "\n",
    "        for sent_id in range(1, len(corpus)+1):\n",
    "            same_keywords = []\n",
    "\n",
    "            for word_dic in corpus[f\"{sent_id}\"]:\n",
    "\n",
    "                for lemma_pos in word_dic[f\"lemmas_pos\"]:\n",
    "                    corpus_lemma = lemma_pos[0]\n",
    "\n",
    "                    if corpus_lemma in lemmata and corpus_lemma not in same_keywords:\n",
    "                        same_keywords.append(corpus_lemma)\n",
    "\n",
    "            if len(same_keywords) >= 2:\n",
    "                word_forms = [dic[\"word_form\"] for dic in corpus[f\"{sent_id}\"]]\n",
    "                sent = \" \".join(word_forms) \n",
    "                lemma_id = f\"{corpus_id}_{sent_id}\"\n",
    "                id_sents = (lemma_id, sent)\n",
    "                sents.append(id_sents)\n",
    "\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences with same keyword but different meaning than 'á¼‚Î½ Î´á½² ÎºÎ±á½¶ Î±á½Ï„Î¿á½¶ Î²Î¬Î½Ï„ÎµÏ‚ á¼Ï€á½¶ ÎºÎ»Î·á¿–ÏƒÎ¹ ÎºÎ±Î¸á¿–Î¶Î¿Î½' are:\n",
      "\n",
      "sentences with same keyword but different meaning than 'á¼‘Î¾á¿†Ï‚ Î´á¾½ á¼‘Î¶ÏŒÎ¼ÎµÎ½Î¿Î¹ Ï€Î¿Î»Î¹á½´Î½ á¼…Î»Î± Ï„ÏÏ€Ï„Î¿Î½ á¼ÏÎµÏ„Î¼Î¿á¿–Ï‚' are:\n",
      "\n",
      "sentences with same keyword but different meaning than 'á¼”Î½Î¸ÎµÎ½ Î´á½² Ï€ÏÎ¿Ï„Î­ÏÏ‰ Ï€Î»Î­Î¿Î¼ÎµÎ½ á¼€ÎºÎ±Ï‡Î®Î¼ÎµÎ½Î¿Î¹ á¼¦Ï„Î¿Ï' are:\n",
      "\n",
      "sentences with same keyword but different meaning than 'á¼„ÏƒÎ¼ÎµÎ½Î¿Î¹ á¼Îº Î¸Î±Î½Î¬Ï„Î¿Î¹Î¿, Ï†Î¯Î»Î¿Ï…Ï‚ á½€Î»Î­ÏƒÎ±Î½Ï„ÎµÏ‚ á¼‘Ï„Î±Î¯ÏÎ¿Ï…Ï‚' are:\n",
      "\n",
      "sentences with same keyword but different meaning than 'Î½á¿†Î± Î¼á½²Î½ Î¿á¼µ Î³Îµ Î¼Î­Î»Î±Î¹Î½Î±Î½ á¼Î»á½¸Ï‚ Î²Î­Î½Î¸Î¿ÏƒÎ´Îµ á¼”ÏÏ…ÏƒÏƒÎ±Î½' are:\n",
      "\n",
      "sentences with same keyword but different meaning than 'Ï„Î¿á½¶ Î´á½² Ï€ÏÏ…Î¼Î½Î®ÏƒÎ¹á¾½ á¼”Î»Ï…ÏƒÎ±Î½' are:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(strings):\n",
    "    print(f\"sentences with same keyword but different meaning than '{sentence}' are:\\n\")\n",
    "    sents = []\n",
    "    lemmata = lemmatize_cltk(sentence)\n",
    "    pos_tags = pos_tag_cltk(sentence)\n",
    "    good_lemmata = []\n",
    "    for lemma, pos in zip(lemmata, pos_tags):\n",
    "        if pos == \"n\" or pos == \"v\":\n",
    "            good_lemmata.append(lemma)\n",
    "    list_sents = find_keyword_sentence(good_lemmata)\n",
    "    for sent in list_sents:\n",
    "        check = False\n",
    "        for para in paraphrases[i]:\n",
    "            if para in sent:\n",
    "                check = True\n",
    "        if check == False:\n",
    "            sents.append(sent)\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
