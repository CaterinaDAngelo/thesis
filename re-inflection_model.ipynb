{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('morph_df.pkl.gz', 'rb') as f:\n",
    "    morph_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>lemma</th>\n",
       "      <th>form</th>\n",
       "      <th>tense</th>\n",
       "      <th>mode</th>\n",
       "      <th>act/mid/p</th>\n",
       "      <th>gender</th>\n",
       "      <th>case</th>\n",
       "      <th>person</th>\n",
       "      <th>number</th>\n",
       "      <th>lemma_tok</th>\n",
       "      <th>form_tok</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλεται</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 8, 23, 4, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅληται</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 10, 23, 4, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλῃ</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 95]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλλεσθε</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 14, 8, 22, 11, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>ἅλλομαι</td>\n",
       "      <td>ἅλλεσθε</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[37, 14, 14, 18, 15, 4, 12]</td>\n",
       "      <td>[37, 14, 14, 8, 22, 11, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329771</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329772</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329773</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329774</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329775</th>\n",
       "      <td>0</td>\n",
       "      <td>ζῳώδης</td>\n",
       "      <td>ζῳῶδες</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[9, 105, 33, 7, 10, 21]</td>\n",
       "      <td>[9, 105, 107, 7, 8, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290544 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        POS    lemma     form  tense  mode  act/mid/p  gender  case  person   \n",
       "0         2  ἅλλομαι   ἅλεται      1     5          2       0     0       3  \\\n",
       "1         2  ἅλλομαι   ἅληται      1     5          2       0     0       3   \n",
       "2         2  ἅλλομαι      ἅλῃ      1     5          2       0     0       2   \n",
       "3         2  ἅλλομαι  ἅλλεσθε      4     2          2       0     0       2   \n",
       "4         2  ἅλλομαι  ἅλλεσθε      7     1          2       0     0       2   \n",
       "...     ...      ...      ...    ...   ...        ...     ...   ...     ...   \n",
       "329771    0   ζῳώδης   ζῳῶδες      0     0          0       2     5       4   \n",
       "329772    0   ζῳώδης   ζῳῶδες      0     0          0       1     5       4   \n",
       "329773    0   ζῳώδης   ζῳῶδες      0     0          0       3     4       4   \n",
       "329774    0   ζῳώδης   ζῳῶδες      0     0          0       3     5       4   \n",
       "329775    0   ζῳώδης   ζῳῶδες      0     0          0       3     1       4   \n",
       "\n",
       "        number                    lemma_tok                    form_tok  \n",
       "0            2  [37, 14, 14, 18, 15, 4, 12]      [37, 14, 8, 23, 4, 12]  \n",
       "1            2  [37, 14, 14, 18, 15, 4, 12]     [37, 14, 10, 23, 4, 12]  \n",
       "2            2  [37, 14, 14, 18, 15, 4, 12]                [37, 14, 95]  \n",
       "3            1  [37, 14, 14, 18, 15, 4, 12]  [37, 14, 14, 8, 22, 11, 8]  \n",
       "4            1  [37, 14, 14, 18, 15, 4, 12]  [37, 14, 14, 8, 22, 11, 8]  \n",
       "...        ...                          ...                         ...  \n",
       "329771       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329772       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329773       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329774       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "329775       2      [9, 105, 33, 7, 10, 21]     [9, 105, 107, 7, 8, 21]  \n",
       "\n",
       "[1290544 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate, Lambda\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ά',\n",
       " 'έ',\n",
       " 'ή',\n",
       " 'ί',\n",
       " 'α',\n",
       " 'β',\n",
       " 'γ',\n",
       " 'δ',\n",
       " 'ε',\n",
       " 'ζ',\n",
       " 'η',\n",
       " 'θ',\n",
       " 'ι',\n",
       " 'κ',\n",
       " 'λ',\n",
       " 'μ',\n",
       " 'ν',\n",
       " 'ξ',\n",
       " 'ο',\n",
       " 'π',\n",
       " 'ρ',\n",
       " 'ς',\n",
       " 'σ',\n",
       " 'τ',\n",
       " 'υ',\n",
       " 'φ',\n",
       " 'χ',\n",
       " 'ψ',\n",
       " 'ω',\n",
       " 'ϊ',\n",
       " 'ϋ',\n",
       " 'ό',\n",
       " 'ύ',\n",
       " 'ώ',\n",
       " 'ἀ',\n",
       " 'ἁ',\n",
       " 'ἄ',\n",
       " 'ἅ',\n",
       " 'ἆ',\n",
       " 'ἇ',\n",
       " 'ἐ',\n",
       " 'ἑ',\n",
       " 'ἔ',\n",
       " 'ἕ',\n",
       " 'ἠ',\n",
       " 'ἡ',\n",
       " 'ἤ',\n",
       " 'ἥ',\n",
       " 'ἦ',\n",
       " 'ἧ',\n",
       " 'ἰ',\n",
       " 'ἱ',\n",
       " 'ἴ',\n",
       " 'ἵ',\n",
       " 'ἶ',\n",
       " 'ἷ',\n",
       " 'ὀ',\n",
       " 'ὁ',\n",
       " 'ὄ',\n",
       " 'ὅ',\n",
       " 'ὐ',\n",
       " 'ὑ',\n",
       " 'ὔ',\n",
       " 'ὕ',\n",
       " 'ὖ',\n",
       " 'ὗ',\n",
       " 'ὠ',\n",
       " 'ὡ',\n",
       " 'ὤ',\n",
       " 'ὥ',\n",
       " 'ὦ',\n",
       " 'ὧ',\n",
       " 'ὶ',\n",
       " 'ᾀ',\n",
       " 'ᾄ',\n",
       " 'ᾅ',\n",
       " 'ᾆ',\n",
       " 'ᾇ',\n",
       " 'ᾐ',\n",
       " 'ᾑ',\n",
       " 'ᾔ',\n",
       " 'ᾕ',\n",
       " 'ᾖ',\n",
       " 'ᾗ',\n",
       " 'ᾠ',\n",
       " 'ᾡ',\n",
       " 'ᾤ',\n",
       " 'ᾦ',\n",
       " 'ᾧ',\n",
       " 'ᾰ',\n",
       " 'ᾱ',\n",
       " 'ᾳ',\n",
       " 'ᾴ',\n",
       " 'ᾶ',\n",
       " 'ᾷ',\n",
       " 'ῃ',\n",
       " 'ῄ',\n",
       " 'ῆ',\n",
       " 'ῇ',\n",
       " 'ῐ',\n",
       " 'ΐ',\n",
       " 'ῖ',\n",
       " 'ῠ',\n",
       " 'ῥ',\n",
       " 'ῦ',\n",
       " 'ῳ',\n",
       " 'ῴ',\n",
       " 'ῶ',\n",
       " 'ῷ',\n",
       " '’']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creo un vocabolario dei caratteri\n",
    "all_characters = set()\n",
    "\n",
    "def collect_unique_chars(word):\n",
    "    for char in word:\n",
    "        all_characters.add(char)\n",
    "\n",
    "morph_df[\"lemma\"].apply(collect_unique_chars)\n",
    "morph_df[\"form\"].apply(collect_unique_chars)\n",
    "\n",
    "char_vocab = (sorted(list(all_characters)))\n",
    "char_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo un dizionario che assegna ad ogni carattere un indice\n",
    "char_to_idx = {char: idx for idx, char in enumerate(char_vocab)}\n",
    "\n",
    "vocab_chars = len(char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['POS', 'lemma', 'form', 'tense', 'mode', 'act/mid/p', 'gender', 'case',\n",
       "       'person', 'number', 'lemma_tok', 'form_tok'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "char_emb_dim = 64\n",
    "max_len = 14\n",
    "input_layers = []\n",
    "# input and embeddings for lemma's characters\n",
    "lemma_input = Input(shape=(14,), name = \"lemma_input\")\n",
    "input_layers.append(lemma_input)\n",
    "lemma_emb = Embedding(input_dim = vocab_chars, output_dim = char_emb_dim, name = \"lemma_emb\")(lemma_input)\n",
    "\n",
    "# #input and embeddings for form's characters\n",
    "# form_input = Input(shape=(None,), name = \"form_input\")\n",
    "# form_emb = Embedding(input_dim = vocab_chars, output_dim = char_emb_dim, name = \"form_emb\")(form_input)\n",
    "\n",
    "\n",
    "# for the features the embeddings will be repeated for every character\n",
    "# input and embeddings for POS\n",
    "pos_input = Input(shape = (1,), name = \"pos_input\")\n",
    "input_layers.append(pos_input)\n",
    "vocab_pos = len(morph_df['POS'].unique())\n",
    "pos_emb_dim = 8\n",
    "pos_emb = Embedding(input_dim = vocab_pos, output_dim = pos_emb_dim, name = \"pos_emb\")(pos_input)\n",
    "pos_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(pos_emb)\n",
    "\n",
    "# input and embeddings for tense\n",
    "tense_input = Input(shape = (1,), name = \"tense_input\")\n",
    "input_layers.append(tense_input)\n",
    "vocab_tense = len(morph_df['tense'].unique())\n",
    "tense_emb_dim = 16\n",
    "tense_emb = Embedding(input_dim = vocab_tense, output_dim = tense_emb_dim, name = \"tense_emb\")(tense_input)\n",
    "tense_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(tense_emb)\n",
    "\n",
    "# input and embedding for mode \n",
    "mode_input = Input(shape = (1,), name = \"mode_input\")\n",
    "input_layers.append(mode_input)\n",
    "vocab_mode = len(morph_df['mode'].unique())\n",
    "mode_emb_dim = 16\n",
    "mode_emb = Embedding(input_dim = vocab_mode, output_dim = mode_emb_dim, name = \"mode_emb\")(mode_input)\n",
    "mode_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(mode_emb)\n",
    "\n",
    "# input and embedding for diathesis\n",
    "diath_input = Input(shape = (1,), name = \"diath_input\")\n",
    "input_layers.append(diath_input)\n",
    "vocab_diath = len(morph_df['act/mid/p'].unique())\n",
    "diath_emb_dim = 8\n",
    "diath_emb = Embedding(input_dim = vocab_diath, output_dim = diath_emb_dim, name = \"diath_emb\")(diath_input)\n",
    "diath_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(diath_emb)\n",
    "\n",
    "# input and embedding for gender\n",
    "gender_input = Input(shape = (1,), name = \"gender_input\")\n",
    "input_layers.append(gender_input)\n",
    "vocab_gender = len(morph_df['gender'].unique())\n",
    "gender_emb_dim = 8\n",
    "gender_emb = Embedding(input_dim = vocab_gender, output_dim = gender_emb_dim, name = \"gender_emb\")(gender_input)\n",
    "gender_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(gender_emb)\n",
    "\n",
    "# input and embedding for case\n",
    "case_input = Input(shape = (1,), name = \"case_input\")\n",
    "input_layers.append(case_input)\n",
    "vocab_case = len(morph_df['case'].unique())\n",
    "case_emb_dim = 16\n",
    "case_emb = Embedding(input_dim = vocab_case, output_dim = case_emb_dim, name = \"case_emb\")(case_input)\n",
    "case_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(case_emb)\n",
    "\n",
    "# input and embedding for person\n",
    "person_input = Input(shape = (1,), name = \"person_input\")\n",
    "input_layers.append(person_input)\n",
    "vocab_person = len(morph_df['person'].unique())\n",
    "person_emb_dim = 8\n",
    "person_emb = Embedding(input_dim = vocab_person, output_dim = person_emb_dim, name = \"person_emb\")(person_input)\n",
    "person_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(person_emb)\n",
    "\n",
    "# input and embedding for number\n",
    "number_input = Input(shape = (1,), name = \"number_input\")\n",
    "input_layers.append(number_input)\n",
    "vocab_number = len(morph_df['number'].unique())\n",
    "number_emb_dim = 8\n",
    "number_emb = Embedding(input_dim = vocab_number, output_dim = number_emb_dim, name = \"number_emb\")(number_input)\n",
    "number_emb_rep = Lambda(lambda x: tf.repeat(x, repeats=max_len, axis=1))(number_emb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of lemma_emb: (None, 14, 64)\n",
      "Shape of pos_emb_repeated: (None, 14, 8)\n",
      "Shape of tense_emb_repeated: (None, 14, 16)\n",
      "Shape of mode_emb_repeated: (None, 14, 16)\n",
      "Shape of diath_emb: (None, 14, 8)\n",
      "Shape of gender_emb_repeated: (None, 14, 8)\n",
      "Shape of case_emb_repeated: (None, 14, 16)\n",
      "Shape of person_emb_repeated: (None, 14, 8)\n",
      "Shape of number_emb: (None, 14, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of lemma_emb: {lemma_emb.shape}\")\n",
    "print(f\"Shape of pos_emb_repeated: {pos_emb_rep.shape}\")\n",
    "print(f\"Shape of tense_emb_repeated: {tense_emb_rep.shape}\")\n",
    "print(f\"Shape of mode_emb_repeated: {mode_emb_rep.shape}\")\n",
    "print(f\"Shape of diath_emb: {diath_emb_rep.shape}\")\n",
    "print(f\"Shape of gender_emb_repeated: {gender_emb_rep.shape}\")\n",
    "print(f\"Shape of case_emb_repeated: {case_emb_rep.shape}\")\n",
    "print(f\"Shape of person_emb_repeated: {person_emb_rep.shape}\")\n",
    "print(f\"Shape of number_emb: {number_emb_rep.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now concatenate all the embeddings:\n",
    "\n",
    "combined_embedding = Concatenate(axis = -1)([\n",
    "    lemma_emb,  # character embeddings for lemma\n",
    "    pos_emb_rep,  # POS embedding\n",
    "    tense_emb_rep,  # tense embedding for verbs/participles\n",
    "    mode_emb_rep,  # mode embedding for verbs/participles\n",
    "    diath_emb_rep,  # diathesis for verbs/participles\n",
    "    gender_emb_rep,  # gender for nouns/participles\n",
    "    case_emb_rep,  # case for nouns/participles\n",
    "    person_emb_rep,  # person for verbs\n",
    "    number_emb_rep, # number for verbs/nouns/participles\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now add lstm and dense layer\n",
    "\n",
    "lstm_output = LSTM(128, return_sequences=True)(combined_embedding)\n",
    "\n",
    "output = Dense(vocab_chars, activation = \"softmax\")(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " pos_input (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " tense_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " diath_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " gender_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " case_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " person_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " number_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lemma_input (InputLayer)    [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " pos_emb (Embedding)         (None, 1, 8)                 24        ['pos_input[0][0]']           \n",
      "                                                                                                  \n",
      " tense_emb (Embedding)       (None, 1, 16)                128       ['tense_input[0][0]']         \n",
      "                                                                                                  \n",
      " mode_emb (Embedding)        (None, 1, 16)                96        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " diath_emb (Embedding)       (None, 1, 8)                 32        ['diath_input[0][0]']         \n",
      "                                                                                                  \n",
      " gender_emb (Embedding)      (None, 1, 8)                 32        ['gender_input[0][0]']        \n",
      "                                                                                                  \n",
      " case_emb (Embedding)        (None, 1, 16)                96        ['case_input[0][0]']          \n",
      "                                                                                                  \n",
      " person_emb (Embedding)      (None, 1, 8)                 40        ['person_input[0][0]']        \n",
      "                                                                                                  \n",
      " number_emb (Embedding)      (None, 1, 8)                 24        ['number_input[0][0]']        \n",
      "                                                                                                  \n",
      " lemma_emb (Embedding)       (None, 14, 64)               7040      ['lemma_input[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)           (None, 14, 8)                0         ['pos_emb[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)           (None, 14, 16)               0         ['tense_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)          (None, 14, 16)               0         ['mode_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)          (None, 14, 8)                0         ['diath_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)          (None, 14, 8)                0         ['gender_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)          (None, 14, 16)               0         ['case_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_14 (Lambda)          (None, 14, 8)                0         ['person_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_15 (Lambda)          (None, 14, 8)                0         ['number_emb[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 152)              0         ['lemma_emb[0][0]',           \n",
      " )                                                                   'lambda_8[0][0]',            \n",
      "                                                                     'lambda_9[0][0]',            \n",
      "                                                                     'lambda_10[0][0]',           \n",
      "                                                                     'lambda_11[0][0]',           \n",
      "                                                                     'lambda_12[0][0]',           \n",
      "                                                                     'lambda_13[0][0]',           \n",
      "                                                                     'lambda_14[0][0]',           \n",
      "                                                                     'lambda_15[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 14, 128)              143872    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 14, 110)              14190     ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 165574 (646.77 KB)\n",
      "Trainable params: 165574 (646.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = input_layers, outputs = output)\n",
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we split the dataframe into training, validation and test set\n",
    "train_df, temp_df = train_test_split(morph_df, test_size=0.3, stratify=morph_df['POS'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['POS'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length covering 95% of lemmata: 12\n",
      "Max length covering 95% of forms: 14\n"
     ]
    }
   ],
   "source": [
    "# we try to determine the best max_len to pad the inflected forms and lemmata\n",
    "# first we understand the distribution of lemmata and inflected forms' length\n",
    "\n",
    "morph_df['lemmata_length'] = morph_df[\"lemma_tok\"].apply(len)\n",
    "morph_df['forms_length'] = morph_df[\"form_tok\"].apply(len)\n",
    "\n",
    "max_len_lemmata = int(morph_df['lemmata_length'].quantile(0.95))\n",
    "print(f\"Max length covering 95% of lemmata: {max_len_lemmata}\")\n",
    "max_len_forms = int(morph_df['forms_length'].quantile(0.95))\n",
    "print(f\"Max length covering 95% of forms: {max_len_forms}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we now create arrays for all the df_train columns\n",
    "pos_train = np.array(train_df[\"POS\"]).reshape(-1, 1)\n",
    "lemma_train = pad_sequences(np.array(train_df[\"lemma_tok\"]), maxlen= max_len, padding = 'post', truncating = 'pre')\n",
    "tense_train = np.array(train_df[\"tense\"]).reshape(-1, 1)\n",
    "mode_train = np.array(train_df[\"mode\"]).reshape(-1, 1)\n",
    "diath_train = np.array(train_df[\"act/mid/p\"]).reshape(-1, 1)\n",
    "gender_train = np.array(train_df[\"gender\"]).reshape(-1, 1)\n",
    "case_train = np.array(train_df[\"case\"]).reshape(-1, 1)\n",
    "person_train = np.array(train_df[\"person\"]).reshape(-1, 1)\n",
    "number_train = np.array(train_df[\"number\"]).reshape(-1, 1)\n",
    "\n",
    "# then we create the labels\n",
    "y_train = pad_sequences(np.array(train_df[\"form_tok\"]), maxlen = max_len, padding = 'post', truncating = 'pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do the same for the validation set\n",
    "pos_val = np.array(val_df[\"POS\"]).reshape(-1, 1)\n",
    "lemma_val = pad_sequences(np.array(val_df[\"lemma_tok\"]), maxlen= max_len, padding = 'post', truncating = 'pre')\n",
    "tense_val = np.array(val_df[\"tense\"]).reshape(-1, 1)\n",
    "mode_val = np.array(val_df[\"mode\"]).reshape(-1, 1)\n",
    "diath_val = np.array(val_df[\"act/mid/p\"]).reshape(-1, 1)\n",
    "gender_val = np.array(val_df[\"gender\"]).reshape(-1, 1)\n",
    "case_val = np.array(val_df[\"case\"]).reshape(-1, 1)\n",
    "person_val = np.array(val_df[\"person\"]).reshape(-1, 1)\n",
    "number_val = np.array(val_df[\"number\"]).reshape(-1, 1)\n",
    "\n",
    "y_val = pad_sequences(np.array(val_df[\"form_tok\"]), maxlen = max_len, padding = 'post', truncating = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {\n",
    "    'pos_input': pos_train,\n",
    "    'lemma_input': lemma_train,\n",
    "    'tense_input': tense_train,\n",
    "    'mode_input': mode_train,\n",
    "    'diath_input': diath_train,\n",
    "    'gender_input': gender_train,\n",
    "    'case_input': case_train,\n",
    "    'person_input': person_train,\n",
    "    'number_input': number_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = {\n",
    "    'pos_input': pos_val,\n",
    "    'lemma_input': lemma_val,\n",
    "    'tense_input': tense_val,\n",
    "    'mode_input': mode_val,\n",
    "    'diath_input': diath_val,\n",
    "    'gender_input': gender_val,\n",
    "    'case_input': case_val,\n",
    "    'person_input': person_val,\n",
    "    'number_input': number_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "28231/28231 [==============================] - 252s 9ms/step - loss: 0.6339 - accuracy: 0.8301 - val_loss: 0.5052 - val_accuracy: 0.8631\n",
      "Epoch 2/5\n",
      "28231/28231 [==============================] - 242s 9ms/step - loss: 0.4773 - accuracy: 0.8699 - val_loss: 0.4622 - val_accuracy: 0.8740\n",
      "Epoch 3/5\n",
      "28231/28231 [==============================] - 251s 9ms/step - loss: 0.4483 - accuracy: 0.8767 - val_loss: 0.4450 - val_accuracy: 0.8779\n",
      "Epoch 4/5\n",
      "28231/28231 [==============================] - 245s 9ms/step - loss: 0.4333 - accuracy: 0.8800 - val_loss: 0.4330 - val_accuracy: 0.8804\n",
      "Epoch 5/5\n",
      "28231/28231 [==============================] - 243s 9ms/step - loss: 0.4238 - accuracy: 0.8821 - val_loss: 0.4267 - val_accuracy: 0.8821\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 5, validation_data = (X_val, y_val), batch_size = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience = 5, verbose = 1, mode = \"min\", restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "28231/28231 [==============================] - 282s 10ms/step - loss: 0.6328 - accuracy: 0.8304 - val_loss: 0.5058 - val_accuracy: 0.8631\n",
      "Epoch 2/20\n",
      "28231/28231 [==============================] - 297s 11ms/step - loss: 0.4798 - accuracy: 0.8690 - val_loss: 0.4635 - val_accuracy: 0.8731\n",
      "Epoch 3/20\n",
      "28231/28231 [==============================] - 287s 10ms/step - loss: 0.4506 - accuracy: 0.8760 - val_loss: 0.4463 - val_accuracy: 0.8777\n",
      "Epoch 4/20\n",
      "28231/28231 [==============================] - 292s 10ms/step - loss: 0.4351 - accuracy: 0.8796 - val_loss: 0.4343 - val_accuracy: 0.8804\n",
      "Epoch 5/20\n",
      "28231/28231 [==============================] - 291s 10ms/step - loss: 0.4251 - accuracy: 0.8818 - val_loss: 0.4302 - val_accuracy: 0.8811\n",
      "Epoch 6/20\n",
      "28231/28231 [==============================] - 298s 11ms/step - loss: 0.4181 - accuracy: 0.8833 - val_loss: 0.4239 - val_accuracy: 0.8822\n",
      "Epoch 7/20\n",
      "28231/28231 [==============================] - 297s 11ms/step - loss: 0.4127 - accuracy: 0.8845 - val_loss: 0.4191 - val_accuracy: 0.8835\n",
      "Epoch 8/20\n",
      "28231/28231 [==============================] - 296s 10ms/step - loss: 0.4087 - accuracy: 0.8854 - val_loss: 0.4158 - val_accuracy: 0.8843\n",
      "Epoch 9/20\n",
      "28231/28231 [==============================] - 297s 11ms/step - loss: 0.4056 - accuracy: 0.8861 - val_loss: 0.4128 - val_accuracy: 0.8848\n",
      "Epoch 10/20\n",
      "28231/28231 [==============================] - 298s 11ms/step - loss: 0.4028 - accuracy: 0.8867 - val_loss: 0.4119 - val_accuracy: 0.8850\n",
      "Epoch 11/20\n",
      "28231/28231 [==============================] - 250s 9ms/step - loss: 0.4003 - accuracy: 0.8872 - val_loss: 0.4097 - val_accuracy: 0.8852\n",
      "Epoch 12/20\n",
      "28231/28231 [==============================] - 246s 9ms/step - loss: 0.3986 - accuracy: 0.8876 - val_loss: 0.4074 - val_accuracy: 0.8862\n",
      "Epoch 13/20\n",
      "28231/28231 [==============================] - 247s 9ms/step - loss: 0.3966 - accuracy: 0.8881 - val_loss: 0.4074 - val_accuracy: 0.8855\n",
      "Epoch 14/20\n",
      "28231/28231 [==============================] - 246s 9ms/step - loss: 0.3950 - accuracy: 0.8883 - val_loss: 0.4040 - val_accuracy: 0.8865\n",
      "Epoch 15/20\n",
      "28231/28231 [==============================] - 245s 9ms/step - loss: 0.3937 - accuracy: 0.8886 - val_loss: 0.4027 - val_accuracy: 0.8867\n",
      "Epoch 16/20\n",
      "28231/28231 [==============================] - 246s 9ms/step - loss: 0.3926 - accuracy: 0.8889 - val_loss: 0.4052 - val_accuracy: 0.8860\n",
      "Epoch 17/20\n",
      "28231/28231 [==============================] - 247s 9ms/step - loss: 0.3913 - accuracy: 0.8891 - val_loss: 0.4020 - val_accuracy: 0.8872\n",
      "Epoch 18/20\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3902 - accuracy: 0.8894 - val_loss: 0.4027 - val_accuracy: 0.8870\n",
      "Epoch 19/20\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3893 - accuracy: 0.8895 - val_loss: 0.4004 - val_accuracy: 0.8873\n",
      "Epoch 20/20\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3885 - accuracy: 0.8897 - val_loss: 0.4008 - val_accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs = 20, \n",
    "                    validation_data = (X_val, y_val), \n",
    "                    batch_size = 32, \n",
    "                    verbose = 1,\n",
    "                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6050/6050 [==============================] - 32s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {index: char for char, index in char_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(seq, idx_to_char):\n",
    "    return \"\".join([idx_to_char.get(index, \"\") for index in seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pred(y_pred, idx_to_char):\n",
    "    y_pred_idx = np.argmax(y_pred, axis = -1)\n",
    "    # we now eliminate the padding\n",
    "    # pad_token = 0\n",
    "    # y_pred_idx_no_pad = [char for seq in y_pred_idx for char in seq if char != pad_token]\n",
    "    return [decode_seq(seq, idx_to_char) for seq in y_pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_decoded = [decode_seq(seq, idx_to_char) for seq in y_val]\n",
    "# y_pred_decoded = decode_pred(y_pred, idx_to_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_chars = [char for seq in y_true_decoded for char in seq]\n",
    "# y_pred_chars = [char for seq in y_pred_decoded for char in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ά       0.96      0.97      0.96    860603\n",
      "           έ       0.81      0.78      0.79     36835\n",
      "           ή       0.75      0.72      0.74     15358\n",
      "           ί       0.82      0.81      0.82     31885\n",
      "           α       0.82      0.84      0.83    152202\n",
      "           β       0.92      0.91      0.92     13170\n",
      "           γ       0.89      0.88      0.88     27088\n",
      "           δ       0.91      0.92      0.91     30238\n",
      "           ε       0.81      0.81      0.81    127631\n",
      "           ζ       0.92      0.92      0.92     11421\n",
      "           η       0.79      0.70      0.74     33765\n",
      "           θ       0.87      0.81      0.84     24968\n",
      "           ι       0.82      0.83      0.82    122062\n",
      "           κ       0.90      0.90      0.90     62215\n",
      "           λ       0.90      0.91      0.90     50805\n",
      "           μ       0.91      0.91      0.91     75617\n",
      "           ν       0.87      0.87      0.87    167920\n",
      "           ξ       0.87      0.81      0.84     12766\n",
      "           ο       0.86      0.86      0.86    138601\n",
      "           π       0.90      0.93      0.91     74853\n",
      "           ρ       0.89      0.90      0.90     81427\n",
      "           ς       0.86      0.86      0.86     36731\n",
      "           σ       0.83      0.86      0.85    110844\n",
      "           τ       0.86      0.86      0.86    106445\n",
      "           υ       0.84      0.86      0.85     53647\n",
      "           φ       0.89      0.91      0.90     18837\n",
      "           χ       0.92      0.90      0.91     16423\n",
      "           ψ       0.93      0.94      0.93      5390\n",
      "           ω       0.84      0.79      0.82     30662\n",
      "           ϊ       1.00      1.00      1.00         4\n",
      "           ό       0.83      0.78      0.81     18511\n",
      "           ύ       0.85      0.84      0.85     19422\n",
      "           ώ       0.76      0.73      0.74      7372\n",
      "           ἀ       0.90      0.98      0.94     27057\n",
      "           ἁ       0.90      0.79      0.84       928\n",
      "           ἄ       0.72      0.45      0.55      1006\n",
      "           ἅ       0.61      0.50      0.55       173\n",
      "           ἆ       0.00      0.00      0.00        28\n",
      "           ἇ       0.00      0.00      0.00         4\n",
      "           ἐ       0.90      0.90      0.90     27433\n",
      "           ἑ       0.88      0.89      0.89      1133\n",
      "           ἔ       0.72      0.19      0.29      1140\n",
      "           ἕ       0.59      0.61      0.60       219\n",
      "           ἠ       0.83      0.22      0.35      1377\n",
      "           ἡ       0.85      0.94      0.89       954\n",
      "           ἤ       0.39      0.06      0.10       236\n",
      "           ἥ       0.70      0.38      0.49       165\n",
      "           ἦ       0.33      0.09      0.14        35\n",
      "           ἧ       0.40      0.36      0.38        28\n",
      "           ἰ       0.84      0.91      0.88      4012\n",
      "           ἱ       0.94      0.87      0.90      1135\n",
      "           ἴ       0.65      0.56      0.60       488\n",
      "           ἵ       0.55      0.53      0.54       160\n",
      "           ἶ       0.63      0.22      0.32        55\n",
      "           ἷ       0.63      0.38      0.47        45\n",
      "           ὀ       0.94      0.96      0.95      2371\n",
      "           ὁ       0.85      0.98      0.91      1086\n",
      "           ὄ       0.70      0.56      0.62       221\n",
      "           ὅ       0.52      0.37      0.43        87\n",
      "           ὐ       0.95      0.94      0.94      3276\n",
      "           ὑ       0.95      0.99      0.97      5788\n",
      "           ὔ       0.64      0.67      0.65       360\n",
      "           ὕ       0.80      0.44      0.57       173\n",
      "           ὖ       1.00      0.06      0.12        16\n",
      "           ὗ       0.64      0.41      0.50        22\n",
      "           ὠ       0.77      0.83      0.80       596\n",
      "           ὡ       0.75      0.86      0.80       206\n",
      "           ὤ       0.50      0.12      0.20       123\n",
      "           ὥ       0.86      0.29      0.43        42\n",
      "           ὦ       0.67      0.06      0.11        34\n",
      "           ὧ       0.33      0.12      0.18         8\n",
      "           ᾀ       0.00      0.00      0.00        19\n",
      "           ᾄ       0.60      0.10      0.17        30\n",
      "           ᾆ       0.00      0.00      0.00        11\n",
      "           ᾐ       0.40      0.58      0.47        85\n",
      "           ᾑ       0.17      0.12      0.14        24\n",
      "           ᾔ       0.17      0.10      0.12        20\n",
      "           ᾕ       0.00      0.00      0.00         2\n",
      "           ᾖ       0.00      0.00      0.00         7\n",
      "           ᾗ       0.00      0.00      0.00         3\n",
      "           ᾠ       0.57      0.54      0.55        94\n",
      "           ᾤ       0.29      0.07      0.11        29\n",
      "           ᾦ       0.00      0.00      0.00         7\n",
      "           ᾧ       0.00      0.00      0.00         1\n",
      "           ᾰ       0.00      0.00      0.00        11\n",
      "           ᾱ       0.50      0.33      0.40        12\n",
      "           ᾳ       0.54      0.49      0.51      1127\n",
      "           ᾴ       0.70      0.41      0.52       114\n",
      "           ᾶ       0.48      0.31      0.38      2296\n",
      "           ᾷ       0.43      0.47      0.45       664\n",
      "           ῃ       0.55      0.56      0.55      5689\n",
      "           ῄ       0.39      0.21      0.27       226\n",
      "           ῆ       0.61      0.41      0.49      2283\n",
      "           ῇ       0.50      0.50      0.50      1408\n",
      "           ῐ       0.60      0.23      0.33        26\n",
      "           ῖ       0.72      0.74      0.73      6596\n",
      "           ῠ       1.00      0.05      0.10        20\n",
      "           ῥ       0.99      0.96      0.97      1166\n",
      "           ῦ       0.81      0.84      0.82     10777\n",
      "           ῳ       0.81      0.79      0.80      2497\n",
      "           ῴ       0.44      0.40      0.42       282\n",
      "           ῶ       0.67      0.70      0.69      8741\n",
      "           ῷ       0.77      0.74      0.76       671\n",
      "           ’       0.34      0.06      0.10      7272\n",
      "\n",
      "    accuracy                           0.89   2710148\n",
      "   macro avg       0.66      0.56      0.58   2710148\n",
      "weighted avg       0.89      0.89      0.89   2710148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_chars, y_pred_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true : ἁρμοστοῦάάάάάά  predicted: ἁρμοστοῦάάάάάά\n",
      "true : μειλίχιεάάάάάά  predicted: μειλίχιεάάάάάά\n",
      "true : ἐνιδόντεςάάάάά  predicted: ἐνδόντεςάάάάάά\n",
      "true : προαπέλαυονάάά  predicted: προαπέλαυονάάά\n",
      "true : φερομέναάάάάάά  predicted: φερομέναάάάάάά\n",
      "true : θνητοίάάάάάάάά  predicted: θνητοίάάάάάάάά\n",
      "true : ἐπαχθεῖσινάάάά  predicted: ἐπαχθήῖινάάάάά\n",
      "true : ἀνοιδέειάάάάάά  predicted: ἀνοιδεῖάάάάάάά\n",
      "true : διακεφαλαιοῦνά  predicted: διακεφαλαιοῦνά\n",
      "true : ἐπαναβᾶσαιάάάά  predicted: ἐπαναβάσαιάάάά\n",
      "true : ᾐσχύγκειάάάάάά  predicted: ᾔιθδυκειάάάάάά\n",
      "true : ἀπογεγραμμέναά  predicted: ἀπογεγραμμέναά\n",
      "true : γήιναάάάάάάάάά  predicted: γήίναάάάάάάάάά\n",
      "true : καταφυσῶνάάάάά  predicted: καταφυσῶνάάάάά\n",
      "true : προσελομένοιςά  predicted: προσγιομένοιςά\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    print(f\"true : {y_true_decoded[i]}  predicted: {y_pred_decoded[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence-level Accuracy: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate sequence-level accuracy.\n",
    "sequence_accuracy = accuracy_score(y_true_decoded, y_pred_decoded)\n",
    "print(f'Sequence-level Accuracy: {sequence_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now create a model with two lstm layers and a Dropout layer\n",
    "lstm_input = LSTM(128, return_sequences=True)(combined_embedding)\n",
    "\n",
    "dropout = Dropout(0.2)(lstm_input)\n",
    "\n",
    "lstm_output = LSTM(64, return_sequences=True)(dropout)\n",
    "\n",
    "second_output = Dense(vocab_chars, activation = \"softmax\")(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " pos_input (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " tense_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " diath_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " gender_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " case_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " person_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " number_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lemma_input (InputLayer)    [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " pos_emb (Embedding)         (None, 1, 8)                 24        ['pos_input[0][0]']           \n",
      "                                                                                                  \n",
      " tense_emb (Embedding)       (None, 1, 16)                128       ['tense_input[0][0]']         \n",
      "                                                                                                  \n",
      " mode_emb (Embedding)        (None, 1, 16)                96        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " diath_emb (Embedding)       (None, 1, 8)                 32        ['diath_input[0][0]']         \n",
      "                                                                                                  \n",
      " gender_emb (Embedding)      (None, 1, 8)                 32        ['gender_input[0][0]']        \n",
      "                                                                                                  \n",
      " case_emb (Embedding)        (None, 1, 16)                96        ['case_input[0][0]']          \n",
      "                                                                                                  \n",
      " person_emb (Embedding)      (None, 1, 8)                 40        ['person_input[0][0]']        \n",
      "                                                                                                  \n",
      " number_emb (Embedding)      (None, 1, 8)                 24        ['number_input[0][0]']        \n",
      "                                                                                                  \n",
      " lemma_emb (Embedding)       (None, 14, 64)               7040      ['lemma_input[0][0]']         \n",
      "                                                                                                  \n",
      " lambda_8 (Lambda)           (None, 14, 8)                0         ['pos_emb[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_9 (Lambda)           (None, 14, 16)               0         ['tense_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)          (None, 14, 16)               0         ['mode_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)          (None, 14, 8)                0         ['diath_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)          (None, 14, 8)                0         ['gender_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_13 (Lambda)          (None, 14, 16)               0         ['case_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_14 (Lambda)          (None, 14, 8)                0         ['person_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_15 (Lambda)          (None, 14, 8)                0         ['number_emb[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 14, 152)              0         ['lemma_emb[0][0]',           \n",
      " )                                                                   'lambda_8[0][0]',            \n",
      "                                                                     'lambda_9[0][0]',            \n",
      "                                                                     'lambda_10[0][0]',           \n",
      "                                                                     'lambda_11[0][0]',           \n",
      "                                                                     'lambda_12[0][0]',           \n",
      "                                                                     'lambda_13[0][0]',           \n",
      "                                                                     'lambda_14[0][0]',           \n",
      "                                                                     'lambda_15[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, 14, 128)              143872    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 14, 128)              0         ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 14, 64)               49408     ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 14, 110)              7150      ['lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 207942 (812.27 KB)\n",
      "Trainable params: 207942 (812.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "second_model = Model(inputs = input_layers, outputs = second_output)\n",
    "second_model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = ['accuracy'])\n",
    "second_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "28231/28231 [==============================] - 420s 15ms/step - loss: 0.6947 - accuracy: 0.8174 - val_loss: 0.4951 - val_accuracy: 0.8671\n",
      "Epoch 2/100\n",
      "28231/28231 [==============================] - 460s 16ms/step - loss: 0.4971 - accuracy: 0.8663 - val_loss: 0.4450 - val_accuracy: 0.8789\n",
      "Epoch 3/100\n",
      "28231/28231 [==============================] - 378s 13ms/step - loss: 0.4636 - accuracy: 0.8741 - val_loss: 0.4285 - val_accuracy: 0.8829\n",
      "Epoch 4/100\n",
      "28231/28231 [==============================] - 334s 12ms/step - loss: 0.4466 - accuracy: 0.8777 - val_loss: 0.4148 - val_accuracy: 0.8857\n",
      "Epoch 5/100\n",
      "28231/28231 [==============================] - 343s 12ms/step - loss: 0.4359 - accuracy: 0.8801 - val_loss: 0.4090 - val_accuracy: 0.8870\n",
      "Epoch 6/100\n",
      "28231/28231 [==============================] - 408s 14ms/step - loss: 0.4282 - accuracy: 0.8818 - val_loss: 0.4029 - val_accuracy: 0.8881\n",
      "Epoch 7/100\n",
      "28231/28231 [==============================] - 474s 17ms/step - loss: 0.4226 - accuracy: 0.8830 - val_loss: 0.3974 - val_accuracy: 0.8892\n",
      "Epoch 8/100\n",
      "28231/28231 [==============================] - 417s 15ms/step - loss: 0.4178 - accuracy: 0.8840 - val_loss: 0.3930 - val_accuracy: 0.8902\n",
      "Epoch 9/100\n",
      "28231/28231 [==============================] - 422s 15ms/step - loss: 0.4144 - accuracy: 0.8846 - val_loss: 0.3922 - val_accuracy: 0.8902\n",
      "Epoch 10/100\n",
      "28231/28231 [==============================] - 410s 15ms/step - loss: 0.4113 - accuracy: 0.8853 - val_loss: 0.3887 - val_accuracy: 0.8911\n",
      "Epoch 11/100\n",
      "28231/28231 [==============================] - 342s 12ms/step - loss: 0.4087 - accuracy: 0.8858 - val_loss: 0.3863 - val_accuracy: 0.8913\n",
      "Epoch 12/100\n",
      "28231/28231 [==============================] - 381s 14ms/step - loss: 0.4064 - accuracy: 0.8863 - val_loss: 0.3831 - val_accuracy: 0.8919\n",
      "Epoch 13/100\n",
      "28231/28231 [==============================] - 428s 15ms/step - loss: 0.4044 - accuracy: 0.8867 - val_loss: 0.3842 - val_accuracy: 0.8919\n",
      "Epoch 14/100\n",
      "28231/28231 [==============================] - 434s 15ms/step - loss: 0.4028 - accuracy: 0.8870 - val_loss: 0.3824 - val_accuracy: 0.8925\n",
      "Epoch 15/100\n",
      "28231/28231 [==============================] - 437s 15ms/step - loss: 0.4015 - accuracy: 0.8873 - val_loss: 0.3819 - val_accuracy: 0.8924\n",
      "Epoch 16/100\n",
      "28231/28231 [==============================] - 437s 15ms/step - loss: 0.4000 - accuracy: 0.8875 - val_loss: 0.3793 - val_accuracy: 0.8927\n",
      "Epoch 17/100\n",
      "28231/28231 [==============================] - 433s 15ms/step - loss: 0.3985 - accuracy: 0.8879 - val_loss: 0.3790 - val_accuracy: 0.8928\n",
      "Epoch 18/100\n",
      "28231/28231 [==============================] - 434s 15ms/step - loss: 0.3975 - accuracy: 0.8882 - val_loss: 0.3790 - val_accuracy: 0.8930\n",
      "Epoch 19/100\n",
      "28231/28231 [==============================] - 435s 15ms/step - loss: 0.3967 - accuracy: 0.8883 - val_loss: 0.3787 - val_accuracy: 0.8931\n",
      "Epoch 20/100\n",
      "28231/28231 [==============================] - 441s 16ms/step - loss: 0.3954 - accuracy: 0.8885 - val_loss: 0.3755 - val_accuracy: 0.8933\n",
      "Epoch 21/100\n",
      "28231/28231 [==============================] - 448s 16ms/step - loss: 0.3948 - accuracy: 0.8886 - val_loss: 0.3761 - val_accuracy: 0.8928\n",
      "Epoch 22/100\n",
      "28231/28231 [==============================] - 20053s 710ms/step - loss: 0.3940 - accuracy: 0.8888 - val_loss: 0.3756 - val_accuracy: 0.8932\n",
      "Epoch 23/100\n",
      "28231/28231 [==============================] - 394s 14ms/step - loss: 0.3930 - accuracy: 0.8890 - val_loss: 0.3750 - val_accuracy: 0.8935\n",
      "Epoch 24/100\n",
      "28231/28231 [==============================] - 454s 16ms/step - loss: 0.3922 - accuracy: 0.8891 - val_loss: 0.3748 - val_accuracy: 0.8936\n",
      "Epoch 25/100\n",
      "28231/28231 [==============================] - 463s 16ms/step - loss: 0.3913 - accuracy: 0.8893 - val_loss: 0.3740 - val_accuracy: 0.8939\n",
      "Epoch 26/100\n",
      "28231/28231 [==============================] - 459s 16ms/step - loss: 0.3909 - accuracy: 0.8894 - val_loss: 0.3727 - val_accuracy: 0.8941\n",
      "Epoch 27/100\n",
      "28231/28231 [==============================] - 455s 16ms/step - loss: 0.3906 - accuracy: 0.8895 - val_loss: 0.3729 - val_accuracy: 0.8944\n",
      "Epoch 28/100\n",
      "28231/28231 [==============================] - 452s 16ms/step - loss: 0.3897 - accuracy: 0.8896 - val_loss: 0.3721 - val_accuracy: 0.8943\n",
      "Epoch 29/100\n",
      "28231/28231 [==============================] - 448s 16ms/step - loss: 0.3892 - accuracy: 0.8897 - val_loss: 0.3715 - val_accuracy: 0.8945\n",
      "Epoch 30/100\n",
      "28231/28231 [==============================] - 430s 15ms/step - loss: 0.3886 - accuracy: 0.8898 - val_loss: 0.3710 - val_accuracy: 0.8946\n",
      "Epoch 31/100\n",
      "28231/28231 [==============================] - 429s 15ms/step - loss: 0.3879 - accuracy: 0.8900 - val_loss: 0.3704 - val_accuracy: 0.8942\n",
      "Epoch 32/100\n",
      "28231/28231 [==============================] - 429s 15ms/step - loss: 0.3878 - accuracy: 0.8901 - val_loss: 0.3712 - val_accuracy: 0.8946\n",
      "Epoch 33/100\n",
      "28231/28231 [==============================] - 429s 15ms/step - loss: 0.3873 - accuracy: 0.8902 - val_loss: 0.3713 - val_accuracy: 0.8945\n",
      "Epoch 34/100\n",
      "28231/28231 [==============================] - 429s 15ms/step - loss: 0.3872 - accuracy: 0.8902 - val_loss: 0.3716 - val_accuracy: 0.8943\n",
      "Epoch 35/100\n",
      "28231/28231 [==============================] - 429s 15ms/step - loss: 0.3867 - accuracy: 0.8903 - val_loss: 0.3696 - val_accuracy: 0.8946\n",
      "Epoch 36/100\n",
      "28231/28231 [==============================] - 428s 15ms/step - loss: 0.3860 - accuracy: 0.8904 - val_loss: 0.3689 - val_accuracy: 0.8946\n",
      "Epoch 37/100\n",
      "28231/28231 [==============================] - 428s 15ms/step - loss: 0.3858 - accuracy: 0.8905 - val_loss: 0.3684 - val_accuracy: 0.8949\n",
      "Epoch 38/100\n",
      "28231/28231 [==============================] - 429s 15ms/step - loss: 0.3859 - accuracy: 0.8904 - val_loss: 0.3705 - val_accuracy: 0.8943\n",
      "Epoch 39/100\n",
      "28231/28231 [==============================] - 430s 15ms/step - loss: 0.3855 - accuracy: 0.8905 - val_loss: 0.3695 - val_accuracy: 0.8948\n",
      "Epoch 40/100\n",
      "28231/28231 [==============================] - 430s 15ms/step - loss: 0.3851 - accuracy: 0.8906 - val_loss: 0.3708 - val_accuracy: 0.8944\n",
      "Epoch 41/100\n",
      "28231/28231 [==============================] - 430s 15ms/step - loss: 0.3848 - accuracy: 0.8907 - val_loss: 0.3690 - val_accuracy: 0.8944\n",
      "Epoch 42/100\n",
      "28229/28231 [============================>.] - ETA: 0s - loss: 0.3846 - accuracy: 0.8906Restoring model weights from the end of the best epoch: 37.\n",
      "28231/28231 [==============================] - 430s 15ms/step - loss: 0.3846 - accuracy: 0.8906 - val_loss: 0.3695 - val_accuracy: 0.8947\n",
      "Epoch 42: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = second_model.fit(X_train, y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data = (X_val, y_val), \n",
    "                    batch_size = 32, \n",
    "                    verbose = 1,\n",
    "                    callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6050/6050 [==============================] - 31s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "second_y_pred = second_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[5.82880348e-05, 4.85383509e-07, 1.02278580e-06, ...,\n",
       "         9.04996341e-07, 4.69977431e-06, 4.28635906e-03],\n",
       "        [3.85297790e-05, 3.64853477e-05, 2.29586349e-05, ...,\n",
       "         8.42665850e-06, 1.72788521e-06, 8.43912931e-05],\n",
       "        [1.54008158e-05, 1.86385605e-05, 2.39327728e-05, ...,\n",
       "         3.60017730e-05, 1.44081832e-06, 1.38114165e-05],\n",
       "        ...,\n",
       "        [9.99955654e-01, 6.30950467e-07, 3.73427014e-07, ...,\n",
       "         1.58731375e-08, 5.40381073e-08, 5.91598052e-07],\n",
       "        [9.99985814e-01, 1.40754054e-07, 1.35468014e-07, ...,\n",
       "         1.10358767e-09, 1.12942953e-08, 2.02389742e-07],\n",
       "        [9.99992371e-01, 5.33752704e-08, 7.87581627e-08, ...,\n",
       "         2.29026034e-10, 3.39627193e-09, 9.11897615e-08]],\n",
       "\n",
       "       [[2.61087971e-05, 9.13921951e-07, 2.24265114e-06, ...,\n",
       "         2.94311440e-06, 1.08078826e-08, 5.38074564e-05],\n",
       "        [3.69079612e-06, 6.08376833e-03, 7.90619306e-05, ...,\n",
       "         5.46143310e-05, 3.54110693e-06, 4.66764868e-05],\n",
       "        [9.06730293e-06, 6.97639098e-06, 6.64136360e-06, ...,\n",
       "         3.00798474e-05, 4.12131430e-06, 5.36975858e-05],\n",
       "        ...,\n",
       "        [9.99972343e-01, 2.72976195e-07, 9.11139125e-07, ...,\n",
       "         4.32333502e-10, 8.37441583e-09, 1.39839506e-06],\n",
       "        [9.99976158e-01, 3.38267654e-07, 3.54835350e-07, ...,\n",
       "         3.47885082e-10, 7.03530700e-09, 1.07375615e-06],\n",
       "        [9.99977946e-01, 2.04087371e-07, 6.61725778e-07, ...,\n",
       "         1.82501958e-10, 4.74773154e-09, 9.79683932e-07]],\n",
       "\n",
       "       [[1.78870323e-05, 1.66655518e-05, 4.92254969e-07, ...,\n",
       "         1.55879241e-06, 1.89039673e-09, 1.23224664e-03],\n",
       "        [4.99548623e-05, 2.35100524e-05, 6.27022973e-06, ...,\n",
       "         6.24484073e-07, 1.86788585e-09, 8.35120545e-07],\n",
       "        [3.27545480e-04, 9.05305060e-05, 9.86460655e-05, ...,\n",
       "         9.47801527e-06, 5.38776987e-08, 1.34636480e-06],\n",
       "        ...,\n",
       "        [9.99989629e-01, 3.28616387e-08, 1.00263691e-07, ...,\n",
       "         6.33302655e-12, 5.00807315e-14, 1.67114749e-08],\n",
       "        [9.99998569e-01, 1.49479238e-08, 7.24861451e-08, ...,\n",
       "         2.15300564e-12, 1.47690545e-14, 6.03032158e-09],\n",
       "        [9.99997497e-01, 4.51061766e-09, 4.20988044e-08, ...,\n",
       "         1.27602117e-12, 6.32415847e-15, 3.09667114e-09]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[3.14090062e-06, 2.59965182e-05, 1.15447222e-07, ...,\n",
       "         3.62947026e-06, 6.02179329e-09, 6.79221237e-03],\n",
       "        [4.77101048e-06, 1.42107710e-05, 3.04526293e-06, ...,\n",
       "         6.90780826e-06, 6.69621514e-08, 1.45718332e-05],\n",
       "        [1.15715757e-05, 2.05640998e-02, 5.08682897e-05, ...,\n",
       "         3.37665057e-04, 4.93699372e-06, 1.95331988e-04],\n",
       "        ...,\n",
       "        [9.99972343e-01, 6.59776447e-08, 4.71985999e-07, ...,\n",
       "         3.87233107e-10, 9.13451537e-11, 2.31511791e-07],\n",
       "        [9.99991059e-01, 2.96307565e-08, 1.59289385e-07, ...,\n",
       "         5.99816308e-11, 3.43178394e-12, 9.50561656e-08],\n",
       "        [9.99984860e-01, 1.46860017e-08, 9.04178492e-08, ...,\n",
       "         2.64351405e-11, 2.09397647e-12, 3.90941608e-08]],\n",
       "\n",
       "       [[3.79325911e-06, 7.23680103e-07, 4.10731715e-09, ...,\n",
       "         3.57028654e-07, 2.63186384e-09, 6.75146119e-04],\n",
       "        [4.97415567e-06, 1.17608342e-05, 7.49190292e-07, ...,\n",
       "         1.03780778e-07, 1.05874609e-09, 1.88308441e-05],\n",
       "        [4.67622476e-06, 3.40676743e-05, 2.94928032e-06, ...,\n",
       "         9.03337877e-07, 6.72514089e-09, 3.77485003e-06],\n",
       "        ...,\n",
       "        [9.99861360e-01, 4.29865167e-07, 2.86580507e-06, ...,\n",
       "         1.89576230e-10, 5.66213076e-10, 7.34881880e-08],\n",
       "        [9.99957442e-01, 2.94808416e-07, 1.27552266e-06, ...,\n",
       "         1.02776614e-10, 3.48312129e-10, 4.54942359e-08],\n",
       "        [9.99974012e-01, 2.39442755e-07, 5.16160583e-07, ...,\n",
       "         8.62007479e-11, 3.73773901e-10, 2.78186967e-08]],\n",
       "\n",
       "       [[1.78029641e-05, 9.13119152e-07, 3.23403881e-08, ...,\n",
       "         4.49733193e-07, 3.41850925e-09, 8.27241107e-04],\n",
       "        [5.45135372e-05, 2.26959492e-05, 1.99157366e-05, ...,\n",
       "         4.41331667e-06, 8.30829450e-09, 6.75818865e-06],\n",
       "        [2.36332025e-02, 2.79544983e-02, 3.14914295e-03, ...,\n",
       "         1.39542413e-03, 1.56999668e-05, 3.59500595e-03],\n",
       "        ...,\n",
       "        [9.99994397e-01, 2.45293048e-08, 1.89236843e-07, ...,\n",
       "         2.15316009e-09, 1.18340095e-11, 8.46873832e-07],\n",
       "        [9.99993920e-01, 6.07709438e-08, 8.25156192e-08, ...,\n",
       "         1.36468226e-09, 5.03199912e-12, 7.65620655e-07],\n",
       "        [9.99996543e-01, 4.87223808e-08, 1.00515599e-07, ...,\n",
       "         1.17614318e-09, 1.50656744e-12, 4.50824814e-07]]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_y_pred_decoded = decode_pred(second_y_pred, idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_y_pred_chars = [char for seq in second_y_pred_decoded for char in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ά       0.96      0.98      0.97    860603\n",
      "           έ       0.84      0.79      0.81     36835\n",
      "           ή       0.76      0.79      0.78     15358\n",
      "           ί       0.84      0.83      0.83     31885\n",
      "           α       0.83      0.85      0.84    152202\n",
      "           β       0.93      0.91      0.92     13170\n",
      "           γ       0.89      0.89      0.89     27088\n",
      "           δ       0.91      0.92      0.91     30238\n",
      "           ε       0.82      0.83      0.82    127631\n",
      "           ζ       0.90      0.94      0.92     11421\n",
      "           η       0.79      0.75      0.77     33765\n",
      "           θ       0.88      0.82      0.85     24968\n",
      "           ι       0.85      0.82      0.83    122062\n",
      "           κ       0.90      0.91      0.90     62215\n",
      "           λ       0.91      0.91      0.91     50805\n",
      "           μ       0.92      0.92      0.92     75617\n",
      "           ν       0.90      0.86      0.88    167920\n",
      "           ξ       0.89      0.81      0.85     12766\n",
      "           ο       0.86      0.87      0.87    138601\n",
      "           π       0.90      0.93      0.92     74853\n",
      "           ρ       0.89      0.91      0.90     81427\n",
      "           ς       0.86      0.88      0.87     36731\n",
      "           σ       0.85      0.87      0.86    110844\n",
      "           τ       0.87      0.88      0.87    106445\n",
      "           υ       0.86      0.86      0.86     53647\n",
      "           φ       0.89      0.91      0.90     18837\n",
      "           χ       0.93      0.91      0.92     16423\n",
      "           ψ       0.92      0.94      0.93      5390\n",
      "           ω       0.85      0.82      0.84     30662\n",
      "           ϊ       1.00      1.00      1.00         4\n",
      "           ό       0.85      0.79      0.82     18511\n",
      "           ύ       0.86      0.87      0.86     19422\n",
      "           ώ       0.79      0.78      0.78      7372\n",
      "           ἀ       0.90      0.98      0.94     27057\n",
      "           ἁ       0.90      0.79      0.84       928\n",
      "           ἄ       0.71      0.45      0.55      1006\n",
      "           ἅ       0.61      0.49      0.54       173\n",
      "           ἆ       0.00      0.00      0.00        28\n",
      "           ἇ       0.00      0.00      0.00         4\n",
      "           ἐ       0.91      0.89      0.90     27433\n",
      "           ἑ       0.86      0.92      0.89      1133\n",
      "           ἔ       0.64      0.24      0.34      1140\n",
      "           ἕ       0.73      0.52      0.61       219\n",
      "           ἠ       0.83      0.22      0.35      1377\n",
      "           ἡ       0.87      0.94      0.90       954\n",
      "           ἤ       0.49      0.08      0.14       236\n",
      "           ἥ       0.63      0.48      0.54       165\n",
      "           ἦ       0.00      0.00      0.00        35\n",
      "           ἧ       0.50      0.04      0.07        28\n",
      "           ἰ       0.84      0.91      0.87      4012\n",
      "           ἱ       0.93      0.89      0.91      1135\n",
      "           ἴ       0.63      0.67      0.65       488\n",
      "           ἵ       0.71      0.39      0.50       160\n",
      "           ἶ       0.53      0.36      0.43        55\n",
      "           ἷ       0.50      0.40      0.44        45\n",
      "           ὀ       0.94      0.95      0.95      2371\n",
      "           ὁ       0.90      0.94      0.92      1086\n",
      "           ὄ       0.68      0.57      0.62       221\n",
      "           ὅ       0.38      0.59      0.46        87\n",
      "           ὐ       0.94      0.95      0.95      3276\n",
      "           ὑ       0.95      0.98      0.97      5788\n",
      "           ὔ       0.74      0.63      0.68       360\n",
      "           ὕ       0.65      0.60      0.62       173\n",
      "           ὖ       0.00      0.00      0.00        16\n",
      "           ὗ       0.80      0.36      0.50        22\n",
      "           ὠ       0.88      0.76      0.82       596\n",
      "           ὡ       0.71      0.92      0.80       206\n",
      "           ὤ       0.40      0.57      0.47       123\n",
      "           ὥ       0.41      0.40      0.41        42\n",
      "           ὦ       0.00      0.00      0.00        34\n",
      "           ὧ       0.00      0.00      0.00         8\n",
      "           ᾀ       0.00      0.00      0.00        19\n",
      "           ᾄ       0.60      0.10      0.17        30\n",
      "           ᾆ       0.00      0.00      0.00        11\n",
      "           ᾐ       0.40      0.51      0.45        85\n",
      "           ᾑ       0.50      0.04      0.08        24\n",
      "           ᾔ       0.28      0.25      0.26        20\n",
      "           ᾕ       0.00      0.00      0.00         2\n",
      "           ᾖ       0.00      0.00      0.00         7\n",
      "           ᾗ       0.00      0.00      0.00         3\n",
      "           ᾠ       0.51      0.62      0.56        94\n",
      "           ᾤ       0.60      0.10      0.18        29\n",
      "           ᾦ       0.00      0.00      0.00         7\n",
      "           ᾧ       0.00      0.00      0.00         1\n",
      "           ᾰ       0.00      0.00      0.00        11\n",
      "           ᾱ       0.00      0.00      0.00        12\n",
      "           ᾳ       0.54      0.70      0.61      1127\n",
      "           ᾴ       0.69      0.46      0.55       114\n",
      "           ᾶ       0.47      0.42      0.44      2296\n",
      "           ᾷ       0.45      0.61      0.52       664\n",
      "           ῃ       0.59      0.55      0.57      5689\n",
      "           ῄ       0.42      0.07      0.12       226\n",
      "           ῆ       0.66      0.42      0.52      2283\n",
      "           ῇ       0.53      0.50      0.52      1408\n",
      "           ῐ       0.00      0.00      0.00        26\n",
      "           ῖ       0.74      0.78      0.76      6596\n",
      "           ῠ       0.00      0.00      0.00        20\n",
      "           ῥ       0.92      0.99      0.95      1166\n",
      "           ῦ       0.82      0.85      0.84     10777\n",
      "           ῳ       0.80      0.84      0.82      2497\n",
      "           ῴ       0.46      0.44      0.45       282\n",
      "           ῶ       0.69      0.74      0.71      8741\n",
      "           ῷ       0.78      0.75      0.76       671\n",
      "           ’       0.39      0.05      0.09      7272\n",
      "\n",
      "    accuracy                           0.89   2710148\n",
      "   macro avg       0.62      0.57      0.58   2710148\n",
      "weighted avg       0.89      0.89      0.89   2710148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_chars, second_y_pred_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence-level Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate sequence-level accuracy.\n",
    "sequence_accuracy = accuracy_score(y_true_decoded, second_y_pred_decoded)\n",
    "print(f'Sequence-level Accuracy: {sequence_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\", \"w\", encoding = \"utf-8\") as outfile:\n",
    "    for i in range(len(y_true_decoded)):\n",
    "        outfile.write(f\"true:  {y_true_decoded[i]} predicted:  {second_y_pred_decoded[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "adam = Adam(learning_rate=0.001)\n",
    "callbacks = [reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now create a model with two lstm layers and a Dropout layer\n",
    "lstm_input = LSTM(128, return_sequences=True)(combined_embedding)\n",
    "\n",
    "dropout = Dropout(0.2)(lstm_input)\n",
    "\n",
    "bi_lstm_output = Bidirectional(LSTM(64, return_sequences=True))(dropout)\n",
    "\n",
    "third_output = Dense(vocab_chars, activation = \"softmax\")(lstm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " pos_input (InputLayer)      [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " tense_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " mode_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " diath_input (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " gender_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " case_input (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " person_input (InputLayer)   [(None, 1)]                  0         []                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " number_input (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " lemma_input (InputLayer)    [(None, 14)]                 0         []                            \n",
      "                                                                                                  \n",
      " pos_emb (Embedding)         (None, 1, 8)                 24        ['pos_input[0][0]']           \n",
      "                                                                                                  \n",
      " tense_emb (Embedding)       (None, 1, 16)                128       ['tense_input[0][0]']         \n",
      "                                                                                                  \n",
      " mode_emb (Embedding)        (None, 1, 16)                96        ['mode_input[0][0]']          \n",
      "                                                                                                  \n",
      " diath_emb (Embedding)       (None, 1, 8)                 32        ['diath_input[0][0]']         \n",
      "                                                                                                  \n",
      " gender_emb (Embedding)      (None, 1, 8)                 32        ['gender_input[0][0]']        \n",
      "                                                                                                  \n",
      " case_emb (Embedding)        (None, 1, 16)                96        ['case_input[0][0]']          \n",
      "                                                                                                  \n",
      " person_emb (Embedding)      (None, 1, 8)                 40        ['person_input[0][0]']        \n",
      "                                                                                                  \n",
      " number_emb (Embedding)      (None, 1, 8)                 24        ['number_input[0][0]']        \n",
      "                                                                                                  \n",
      " lemma_emb (Embedding)       (None, 14, 64)               7040      ['lemma_input[0][0]']         \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 14, 8)                0         ['pos_emb[0][0]']             \n",
      "                                                                                                  \n",
      " lambda_1 (Lambda)           (None, 14, 16)               0         ['tense_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)           (None, 14, 16)               0         ['mode_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_3 (Lambda)           (None, 14, 8)                0         ['diath_emb[0][0]']           \n",
      "                                                                                                  \n",
      " lambda_4 (Lambda)           (None, 14, 8)                0         ['gender_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_5 (Lambda)           (None, 14, 16)               0         ['case_emb[0][0]']            \n",
      "                                                                                                  \n",
      " lambda_6 (Lambda)           (None, 14, 8)                0         ['person_emb[0][0]']          \n",
      "                                                                                                  \n",
      " lambda_7 (Lambda)           (None, 14, 8)                0         ['number_emb[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 14, 152)              0         ['lemma_emb[0][0]',           \n",
      "                                                                     'lambda[0][0]',              \n",
      "                                                                     'lambda_1[0][0]',            \n",
      "                                                                     'lambda_2[0][0]',            \n",
      "                                                                     'lambda_3[0][0]',            \n",
      "                                                                     'lambda_4[0][0]',            \n",
      "                                                                     'lambda_5[0][0]',            \n",
      "                                                                     'lambda_6[0][0]',            \n",
      "                                                                     'lambda_7[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 14, 128)              143872    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 14, 110)              14190     ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 165574 (646.77 KB)\n",
      "Trainable params: 165574 (646.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "third_model = Model(inputs = input_layers, outputs = third_output)\n",
    "third_model.compile(optimizer = adam, loss = \"sparse_categorical_crossentropy\", metrics = ['accuracy'])\n",
    "third_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "28231/28231 [==============================] - 387s 14ms/step - loss: 0.6351 - accuracy: 0.8300 - val_loss: 0.5158 - val_accuracy: 0.8597 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "28231/28231 [==============================] - 385s 14ms/step - loss: 0.4788 - accuracy: 0.8695 - val_loss: 0.4658 - val_accuracy: 0.8730 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "28231/28231 [==============================] - 395s 14ms/step - loss: 0.4499 - accuracy: 0.8764 - val_loss: 0.4471 - val_accuracy: 0.8775 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "28231/28231 [==============================] - 401s 14ms/step - loss: 0.4346 - accuracy: 0.8799 - val_loss: 0.4383 - val_accuracy: 0.8793 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "28231/28231 [==============================] - 271s 10ms/step - loss: 0.4250 - accuracy: 0.8819 - val_loss: 0.4304 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "28231/28231 [==============================] - 301s 11ms/step - loss: 0.4184 - accuracy: 0.8834 - val_loss: 0.4238 - val_accuracy: 0.8822 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "28231/28231 [==============================] - 306s 11ms/step - loss: 0.4132 - accuracy: 0.8844 - val_loss: 0.4201 - val_accuracy: 0.8829 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "28231/28231 [==============================] - 306s 11ms/step - loss: 0.4092 - accuracy: 0.8853 - val_loss: 0.4191 - val_accuracy: 0.8835 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "28231/28231 [==============================] - 315s 11ms/step - loss: 0.4059 - accuracy: 0.8860 - val_loss: 0.4124 - val_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "28231/28231 [==============================] - 284s 10ms/step - loss: 0.4031 - accuracy: 0.8866 - val_loss: 0.4108 - val_accuracy: 0.8855 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "28231/28231 [==============================] - 251s 9ms/step - loss: 0.4009 - accuracy: 0.8871 - val_loss: 0.4098 - val_accuracy: 0.8859 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "28231/28231 [==============================] - 253s 9ms/step - loss: 0.3990 - accuracy: 0.8874 - val_loss: 0.4083 - val_accuracy: 0.8856 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "28231/28231 [==============================] - 266s 9ms/step - loss: 0.3974 - accuracy: 0.8878 - val_loss: 0.4094 - val_accuracy: 0.8852 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "28231/28231 [==============================] - 269s 10ms/step - loss: 0.3959 - accuracy: 0.8881 - val_loss: 0.4037 - val_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "28231/28231 [==============================] - 269s 10ms/step - loss: 0.3946 - accuracy: 0.8884 - val_loss: 0.4069 - val_accuracy: 0.8861 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "28231/28231 [==============================] - 272s 10ms/step - loss: 0.3933 - accuracy: 0.8886 - val_loss: 0.4033 - val_accuracy: 0.8866 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "28231/28231 [==============================] - 265s 9ms/step - loss: 0.3923 - accuracy: 0.8888 - val_loss: 0.4051 - val_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3914 - accuracy: 0.8889 - val_loss: 0.4021 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3907 - accuracy: 0.8891 - val_loss: 0.4033 - val_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3899 - accuracy: 0.8893 - val_loss: 0.4004 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3890 - accuracy: 0.8895 - val_loss: 0.4012 - val_accuracy: 0.8870 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "28231/28231 [==============================] - 251s 9ms/step - loss: 0.3885 - accuracy: 0.8895 - val_loss: 0.4010 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "28231/28231 [==============================] - 250s 9ms/step - loss: 0.3880 - accuracy: 0.8897 - val_loss: 0.3981 - val_accuracy: 0.8876 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3872 - accuracy: 0.8899 - val_loss: 0.3989 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3867 - accuracy: 0.8900 - val_loss: 0.3980 - val_accuracy: 0.8879 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "28231/28231 [==============================] - 250s 9ms/step - loss: 0.3861 - accuracy: 0.8901 - val_loss: 0.4006 - val_accuracy: 0.8869 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "28231/28231 [==============================] - 250s 9ms/step - loss: 0.3857 - accuracy: 0.8902 - val_loss: 0.3997 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3851 - accuracy: 0.8903 - val_loss: 0.3988 - val_accuracy: 0.8877 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3701 - accuracy: 0.8940 - val_loss: 0.3848 - val_accuracy: 0.8906 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3670 - accuracy: 0.8946 - val_loss: 0.3835 - val_accuracy: 0.8911 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "28231/28231 [==============================] - 248s 9ms/step - loss: 0.3660 - accuracy: 0.8948 - val_loss: 0.3828 - val_accuracy: 0.8912 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3653 - accuracy: 0.8949 - val_loss: 0.3824 - val_accuracy: 0.8911 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "28231/28231 [==============================] - 250s 9ms/step - loss: 0.3647 - accuracy: 0.8950 - val_loss: 0.3845 - val_accuracy: 0.8907 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "28231/28231 [==============================] - 249s 9ms/step - loss: 0.3643 - accuracy: 0.8951 - val_loss: 0.3831 - val_accuracy: 0.8908 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "28231/28231 [==============================] - 324s 11ms/step - loss: 0.3638 - accuracy: 0.8953 - val_loss: 0.3819 - val_accuracy: 0.8912 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "28231/28231 [==============================] - 378s 13ms/step - loss: 0.3634 - accuracy: 0.8953 - val_loss: 0.3820 - val_accuracy: 0.8911 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "28231/28231 [==============================] - 377s 13ms/step - loss: 0.3632 - accuracy: 0.8954 - val_loss: 0.3821 - val_accuracy: 0.8911 - lr: 5.0000e-04\n",
      "Epoch 38/100\n",
      "28231/28231 [==============================] - 376s 13ms/step - loss: 0.3628 - accuracy: 0.8954 - val_loss: 0.3816 - val_accuracy: 0.8914 - lr: 5.0000e-04\n",
      "Epoch 39/100\n",
      "28231/28231 [==============================] - 377s 13ms/step - loss: 0.3625 - accuracy: 0.8954 - val_loss: 0.3810 - val_accuracy: 0.8915 - lr: 5.0000e-04\n",
      "Epoch 40/100\n",
      "28231/28231 [==============================] - 376s 13ms/step - loss: 0.3622 - accuracy: 0.8955 - val_loss: 0.3813 - val_accuracy: 0.8913 - lr: 5.0000e-04\n",
      "Epoch 41/100\n",
      "28231/28231 [==============================] - 379s 13ms/step - loss: 0.3621 - accuracy: 0.8955 - val_loss: 0.3815 - val_accuracy: 0.8912 - lr: 5.0000e-04\n",
      "Epoch 42/100\n",
      "28231/28231 [==============================] - 379s 13ms/step - loss: 0.3617 - accuracy: 0.8956 - val_loss: 0.3814 - val_accuracy: 0.8913 - lr: 5.0000e-04\n",
      "Epoch 43/100\n",
      "28231/28231 [==============================] - 378s 13ms/step - loss: 0.3538 - accuracy: 0.8977 - val_loss: 0.3748 - val_accuracy: 0.8928 - lr: 2.5000e-04\n",
      "Epoch 44/100\n",
      "28231/28231 [==============================] - 379s 13ms/step - loss: 0.3526 - accuracy: 0.8980 - val_loss: 0.3746 - val_accuracy: 0.8929 - lr: 2.5000e-04\n",
      "Epoch 45/100\n",
      "28231/28231 [==============================] - 377s 13ms/step - loss: 0.3521 - accuracy: 0.8980 - val_loss: 0.3744 - val_accuracy: 0.8929 - lr: 2.5000e-04\n",
      "Epoch 46/100\n",
      "28231/28231 [==============================] - 375s 13ms/step - loss: 0.3518 - accuracy: 0.8980 - val_loss: 0.3744 - val_accuracy: 0.8928 - lr: 2.5000e-04\n",
      "Epoch 47/100\n",
      "28231/28231 [==============================] - 376s 13ms/step - loss: 0.3515 - accuracy: 0.8981 - val_loss: 0.3748 - val_accuracy: 0.8927 - lr: 2.5000e-04\n",
      "Epoch 48/100\n",
      "28231/28231 [==============================] - 9628s 341ms/step - loss: 0.3513 - accuracy: 0.8981 - val_loss: 0.3747 - val_accuracy: 0.8928 - lr: 2.5000e-04\n",
      "Epoch 49/100\n",
      "28231/28231 [==============================] - 310s 11ms/step - loss: 0.3471 - accuracy: 0.8992 - val_loss: 0.3720 - val_accuracy: 0.8933 - lr: 1.2500e-04\n",
      "Epoch 50/100\n",
      "28231/28231 [==============================] - 314s 11ms/step - loss: 0.3465 - accuracy: 0.8994 - val_loss: 0.3722 - val_accuracy: 0.8932 - lr: 1.2500e-04\n",
      "Epoch 51/100\n",
      "28231/28231 [==============================] - 309s 11ms/step - loss: 0.3463 - accuracy: 0.8994 - val_loss: 0.3718 - val_accuracy: 0.8934 - lr: 1.2500e-04\n",
      "Epoch 52/100\n",
      "28231/28231 [==============================] - 306s 11ms/step - loss: 0.3461 - accuracy: 0.8994 - val_loss: 0.3719 - val_accuracy: 0.8932 - lr: 1.2500e-04\n",
      "Epoch 53/100\n",
      "28231/28231 [==============================] - 305s 11ms/step - loss: 0.3460 - accuracy: 0.8995 - val_loss: 0.3719 - val_accuracy: 0.8935 - lr: 1.2500e-04\n",
      "Epoch 54/100\n",
      "28231/28231 [==============================] - 306s 11ms/step - loss: 0.3458 - accuracy: 0.8995 - val_loss: 0.3718 - val_accuracy: 0.8933 - lr: 1.2500e-04\n",
      "Epoch 55/100\n",
      "28231/28231 [==============================] - 307s 11ms/step - loss: 0.3436 - accuracy: 0.9002 - val_loss: 0.3707 - val_accuracy: 0.8936 - lr: 6.2500e-05\n",
      "Epoch 56/100\n",
      "28231/28231 [==============================] - 307s 11ms/step - loss: 0.3433 - accuracy: 0.9002 - val_loss: 0.3708 - val_accuracy: 0.8936 - lr: 6.2500e-05\n",
      "Epoch 57/100\n",
      "28231/28231 [==============================] - 308s 11ms/step - loss: 0.3432 - accuracy: 0.9003 - val_loss: 0.3709 - val_accuracy: 0.8936 - lr: 6.2500e-05\n",
      "Epoch 58/100\n",
      "28231/28231 [==============================] - 308s 11ms/step - loss: 0.3431 - accuracy: 0.9002 - val_loss: 0.3708 - val_accuracy: 0.8937 - lr: 6.2500e-05\n",
      "Epoch 59/100\n",
      "28231/28231 [==============================] - 309s 11ms/step - loss: 0.3419 - accuracy: 0.9006 - val_loss: 0.3706 - val_accuracy: 0.8937 - lr: 3.1250e-05\n",
      "Epoch 60/100\n",
      "28231/28231 [==============================] - 305s 11ms/step - loss: 0.3417 - accuracy: 0.9007 - val_loss: 0.3704 - val_accuracy: 0.8937 - lr: 3.1250e-05\n",
      "Epoch 61/100\n",
      "28231/28231 [==============================] - 273s 10ms/step - loss: 0.3417 - accuracy: 0.9006 - val_loss: 0.3705 - val_accuracy: 0.8937 - lr: 3.1250e-05\n",
      "Epoch 62/100\n",
      "28231/28231 [==============================] - 271s 10ms/step - loss: 0.3416 - accuracy: 0.9007 - val_loss: 0.3705 - val_accuracy: 0.8937 - lr: 3.1250e-05\n",
      "Epoch 63/100\n",
      "28231/28231 [==============================] - 271s 10ms/step - loss: 0.3416 - accuracy: 0.9007 - val_loss: 0.3705 - val_accuracy: 0.8936 - lr: 3.1250e-05\n",
      "Epoch 64/100\n",
      "28231/28231 [==============================] - 272s 10ms/step - loss: 0.3409 - accuracy: 0.9009 - val_loss: 0.3704 - val_accuracy: 0.8937 - lr: 1.5625e-05\n",
      "Epoch 65/100\n",
      "28231/28231 [==============================] - 275s 10ms/step - loss: 0.3409 - accuracy: 0.9009 - val_loss: 0.3704 - val_accuracy: 0.8937 - lr: 1.5625e-05\n",
      "Epoch 66/100\n",
      "28231/28231 [==============================] - 272s 10ms/step - loss: 0.3408 - accuracy: 0.9009 - val_loss: 0.3704 - val_accuracy: 0.8937 - lr: 1.5625e-05\n",
      "Epoch 67/100\n",
      "28231/28231 [==============================] - 273s 10ms/step - loss: 0.3405 - accuracy: 0.9010 - val_loss: 0.3704 - val_accuracy: 0.8938 - lr: 7.8125e-06\n",
      "Epoch 68/100\n",
      "28231/28231 [==============================] - 274s 10ms/step - loss: 0.3404 - accuracy: 0.9010 - val_loss: 0.3704 - val_accuracy: 0.8937 - lr: 7.8125e-06\n",
      "Epoch 69/100\n",
      "28231/28231 [==============================] - 272s 10ms/step - loss: 0.3404 - accuracy: 0.9010 - val_loss: 0.3704 - val_accuracy: 0.8937 - lr: 7.8125e-06\n"
     ]
    }
   ],
   "source": [
    "history = third_model.fit(X_train, y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data = (X_val, y_val), \n",
    "                    batch_size = 32, \n",
    "                    verbose = 1,\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6050/6050 [==============================] - 28s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "third_y_pred = third_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_y_pred_decoded = decode_pred(third_y_pred, idx_to_char)\n",
    "third_y_pred_chars = [char for seq in third_y_pred_decoded for char in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           ά       0.96      0.97      0.97    860603\n",
      "           έ       0.82      0.79      0.81     36835\n",
      "           ή       0.76      0.76      0.76     15358\n",
      "           ί       0.83      0.82      0.83     31885\n",
      "           α       0.83      0.85      0.84    152202\n",
      "           β       0.92      0.91      0.92     13170\n",
      "           γ       0.90      0.89      0.90     27088\n",
      "           δ       0.91      0.92      0.92     30238\n",
      "           ε       0.81      0.82      0.82    127631\n",
      "           ζ       0.92      0.93      0.92     11421\n",
      "           η       0.79      0.73      0.76     33765\n",
      "           θ       0.88      0.82      0.85     24968\n",
      "           ι       0.83      0.83      0.83    122062\n",
      "           κ       0.90      0.91      0.90     62215\n",
      "           λ       0.91      0.91      0.91     50805\n",
      "           μ       0.92      0.92      0.92     75617\n",
      "           ν       0.89      0.87      0.88    167920\n",
      "           ξ       0.90      0.81      0.85     12766\n",
      "           ο       0.86      0.87      0.87    138601\n",
      "           π       0.90      0.93      0.92     74853\n",
      "           ρ       0.90      0.91      0.90     81427\n",
      "           ς       0.86      0.87      0.87     36731\n",
      "           σ       0.84      0.87      0.86    110844\n",
      "           τ       0.87      0.87      0.87    106445\n",
      "           υ       0.85      0.86      0.86     53647\n",
      "           φ       0.90      0.91      0.90     18837\n",
      "           χ       0.92      0.91      0.92     16423\n",
      "           ψ       0.94      0.94      0.94      5390\n",
      "           ω       0.86      0.81      0.83     30662\n",
      "           ϊ       1.00      1.00      1.00         4\n",
      "           ό       0.84      0.80      0.82     18511\n",
      "           ύ       0.86      0.86      0.86     19422\n",
      "           ώ       0.77      0.77      0.77      7372\n",
      "           ἀ       0.90      0.97      0.94     27057\n",
      "           ἁ       0.89      0.79      0.84       928\n",
      "           ἄ       0.68      0.52      0.59      1006\n",
      "           ἅ       0.63      0.49      0.55       173\n",
      "           ἆ       0.00      0.00      0.00        28\n",
      "           ἇ       0.00      0.00      0.00         4\n",
      "           ἐ       0.91      0.90      0.90     27433\n",
      "           ἑ       0.87      0.91      0.89      1133\n",
      "           ἔ       0.70      0.22      0.33      1140\n",
      "           ἕ       0.69      0.63      0.66       219\n",
      "           ἠ       0.84      0.22      0.35      1377\n",
      "           ἡ       0.87      0.93      0.90       954\n",
      "           ἤ       0.69      0.09      0.16       236\n",
      "           ἥ       0.61      0.45      0.52       165\n",
      "           ἦ       0.50      0.11      0.19        35\n",
      "           ἧ       0.90      0.32      0.47        28\n",
      "           ἰ       0.84      0.91      0.88      4012\n",
      "           ἱ       0.92      0.91      0.91      1135\n",
      "           ἴ       0.66      0.61      0.64       488\n",
      "           ἵ       0.70      0.39      0.50       160\n",
      "           ἶ       0.59      0.55      0.57        55\n",
      "           ἷ       0.64      0.36      0.46        45\n",
      "           ὀ       0.92      0.97      0.95      2371\n",
      "           ὁ       0.87      0.96      0.91      1086\n",
      "           ὄ       0.71      0.54      0.61       221\n",
      "           ὅ       0.47      0.46      0.47        87\n",
      "           ὐ       0.94      0.95      0.95      3276\n",
      "           ὑ       0.95      0.99      0.97      5788\n",
      "           ὔ       0.74      0.62      0.68       360\n",
      "           ὕ       0.85      0.54      0.66       173\n",
      "           ὖ       0.33      0.12      0.18        16\n",
      "           ὗ       0.83      0.68      0.75        22\n",
      "           ὠ       0.89      0.76      0.82       596\n",
      "           ὡ       0.77      0.86      0.82       206\n",
      "           ὤ       0.43      0.34      0.38       123\n",
      "           ὥ       0.61      0.48      0.53        42\n",
      "           ὦ       1.00      0.03      0.06        34\n",
      "           ὧ       1.00      0.12      0.22         8\n",
      "           ᾀ       0.00      0.00      0.00        19\n",
      "           ᾄ       0.50      0.03      0.06        30\n",
      "           ᾆ       0.00      0.00      0.00        11\n",
      "           ᾐ       0.38      0.46      0.41        85\n",
      "           ᾑ       0.00      0.00      0.00        24\n",
      "           ᾔ       0.24      0.30      0.27        20\n",
      "           ᾕ       0.00      0.00      0.00         2\n",
      "           ᾖ       0.00      0.00      0.00         7\n",
      "           ᾗ       0.00      0.00      0.00         3\n",
      "           ᾠ       0.64      0.57      0.61        94\n",
      "           ᾤ       0.27      0.10      0.15        29\n",
      "           ᾦ       0.00      0.00      0.00         7\n",
      "           ᾧ       0.00      0.00      0.00         1\n",
      "           ᾰ       0.00      0.00      0.00        11\n",
      "           ᾱ       0.58      0.92      0.71        12\n",
      "           ᾳ       0.53      0.55      0.54      1127\n",
      "           ᾴ       0.62      0.47      0.54       114\n",
      "           ᾶ       0.50      0.34      0.40      2296\n",
      "           ᾷ       0.44      0.54      0.49       664\n",
      "           ῃ       0.62      0.45      0.52      5689\n",
      "           ῄ       0.50      0.22      0.31       226\n",
      "           ῆ       0.64      0.40      0.49      2283\n",
      "           ῇ       0.54      0.47      0.50      1408\n",
      "           ῐ       0.50      0.19      0.28        26\n",
      "           ῖ       0.76      0.74      0.75      6596\n",
      "           ῠ       0.77      0.50      0.61        20\n",
      "           ῥ       0.98      0.96      0.97      1166\n",
      "           ῦ       0.83      0.85      0.84     10777\n",
      "           ῳ       0.78      0.85      0.81      2497\n",
      "           ῴ       0.52      0.37      0.43       282\n",
      "           ῶ       0.71      0.72      0.71      8741\n",
      "           ῷ       0.76      0.81      0.78       671\n",
      "           ’       0.37      0.08      0.14      7272\n",
      "\n",
      "    accuracy                           0.89   2710148\n",
      "   macro avg       0.68      0.59      0.61   2710148\n",
      "weighted avg       0.89      0.89      0.89   2710148\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_chars, third_y_pred_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence-level Accuracy: 0.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate sequence-level accuracy.\n",
    "sequence_accuracy = accuracy_score(y_true_decoded, third_y_pred_decoded)\n",
    "print(f'Sequence-level Accuracy: {sequence_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"third_model_results.txt\", \"w\", encoding = \"utf-8\") as outfile:\n",
    "    for i in range(len(y_true_decoded)):\n",
    "        outfile.write(f\"true:  {y_true_decoded[i]} predicted:  {third_y_pred_decoded[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
